{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Organize, filter, and clean excel file \n",
    "- original file has multiple sheets (for different data set types (e.g. single visit, imaging, labs etc)\n",
    "- only interested in deployed controls ('C') and mTBI ('T')\n",
    "- each participant can have multiple visits for each visit sequence (1-3 visit sequences per participant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting and working with data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import datetime as dt\n",
    "import string\n",
    "\n",
    "#visualizing results\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_context(\"poster\")\n",
    "sns.set_style(\"ticks\")\n",
    "#import yellowbrick as yb\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 15000)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## explore file contents and visit meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = 'C:/Users/Schindler/Documents/Schindler_Lab/Data/Clinical projects/PeskindTBI/freeze_200219/TBIFreeze_20200428_python.xlsx'\n",
    "\n",
    "whole_file = pd.ExcelFile(path_data)\n",
    "#get list of sheet names in file\n",
    "print(whole_file.sheet_names, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#original file has multiple sheets (for different data set types (e.g. single visit, imaging, labs etc)\n",
    "#only interested in deployed controls ('C') and mTBI ('T')\n",
    "#each participant can have multiple visits for each visit sequence (1-3 visit sequences per participant)\n",
    "#first want to explore pattern of visits and determine which sheets have multiple visits per visit sequence\n",
    "\n",
    "for sheet in whole_file.sheet_names:\n",
    "    \n",
    "    sheet_data_int = pd.DataFrame()\n",
    "    \n",
    "    print('Sheet being processed:\\n', sheet)\n",
    "    \n",
    "    #create intermediate dataframe\n",
    "    data_int = pd.DataFrame(data = pd.read_excel(whole_file, sheet))\n",
    "\n",
    "    #select only TBIID C and T (control and TBI)\n",
    "    data_int = data_int[data_int['TBIID'].str.match(r'[CT]\\d\\d')]\n",
    "    print('Data shape only deployed controls and mTBI groups:\\n', data_int.shape)\n",
    "\n",
    "    #meta data\n",
    "    visit_sequences = data_int['VisitSeq'].unique()\n",
    "    print('Number of visit sequences:\\n', len(visit_sequences))\n",
    "    print('Visit seq breakdown:\\n', visit_sequences)\n",
    "    \n",
    "    #meta data\n",
    "    participants_total = data_int['TBIID'].unique()\n",
    "    print('Number of participants:\\n', len(participants_total), '\\n')\n",
    "    \n",
    "    #for each visit\n",
    "    for visit in visit_sequences:\n",
    "        #determine max number of visits for this visit sequence\n",
    "        data_int_visit = data_int[data_int['VisitSeq'] == visit]\n",
    "        max_visits = data_int_visit.groupby('TBIID')['TBIID'].count().max()\n",
    "        print(f'In visits sequence {visit} there is/are a max of {max_visits} visit(s) \\n')\n",
    "        \n",
    "    print('\\n', '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combine sheets and use mean for sheets with multiple visits per sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#some sheets have multiple visits per visit sequence and some sheets have a single visit for each visit sequence\n",
    "#use mean across visits for sheets that have data from multiple visits within a visit sequence\n",
    "\n",
    "data_visit_mean = pd.DataFrame()\n",
    "\n",
    "for sheet in whole_file.sheet_names:\n",
    "    \n",
    "    sheet_data = pd.DataFrame()\n",
    "    \n",
    "    print('Sheet being processed:\\n', sheet)\n",
    "    \n",
    "    #create intermediate dataframe\n",
    "    data_sheet = pd.DataFrame(data = pd.read_excel(whole_file, sheet))\n",
    "\n",
    "    #select only TBIID C and T (control and TBI)\n",
    "    data_sheet = data_sheet[data_sheet['TBIID'].str.match(r'[CT]\\d\\d')]\n",
    "    print('Data shape only deployed controls and mTBI groups:\\n', data_sheet.shape)\n",
    "\n",
    "    #meta data\n",
    "    visit_sequences = data_sheet['VisitSeq'].unique()\n",
    "    print('Number of visit sequences:\\n', len(visit_sequences))\n",
    "    \n",
    "    #meta data\n",
    "    participants_total = data_sheet['TBIID'].unique()\n",
    "    print('Number of participants:\\n', len(participants_total), '\\n')\n",
    "    \n",
    "    #clean\n",
    "    data_sheet = data_sheet.replace({-999.0: np.nan, 999: np.nan, 'None': np.nan})\n",
    "    \n",
    "    #for each visit\n",
    "    for visit in visit_sequences:\n",
    "        print('Visit sequence being processed:\\n', visit)\n",
    "        \n",
    "        #get visit data\n",
    "        data_sheet_visit = data_sheet[data_sheet['VisitSeq'] == visit]\n",
    "\n",
    "        #determine max number of visits for this visit sequence\n",
    "        max_visits = data_sheet_visit.groupby('TBIID')['TBIID'].count().max()\n",
    "\n",
    "        #make new df to fill with cleaned data\n",
    "        data_sheet_visit_merge = pd.DataFrame()\n",
    "\n",
    "        #if only one visit per TBIID in visit sequence, do nothing\n",
    "        if max_visits == 1:\n",
    "            data_sheet_visit_merge = data_sheet_visit_merge.append(data_sheet_visit, ignore_index=True, sort=False)\n",
    "        #if more than one visit per TBIID in visit sequence then need to get mean across visits\n",
    "        else:\n",
    "            for TBIID in data_sheet_visit['TBIID'].unique():\n",
    "                data_sheet_visit_TBIID = data_sheet_visit[data_sheet_visit['TBIID'] == TBIID]\n",
    "                data_sheet_visit_TBIID_mean = data_sheet_visit_TBIID.mean()\n",
    "                data_sheet_visit_TBIID_mean['TBIID'] = TBIID\n",
    "                data_sheet_visit_TBIID_mean['VisitSeq'] = visit\n",
    "                data_sheet_visit_merge = data_sheet_visit_merge.append(data_sheet_visit_TBIID_mean, ignore_index=True, sort=False)\n",
    "        \n",
    "        #combine visit seq with other seq from same sheet\n",
    "        print('Data shape for current visit sequence:\\n', data_sheet_visit_merge.shape, '\\n')\n",
    "        sheet_data = sheet_data.append(data_sheet_visit_merge, ignore_index=True, sort=False)\n",
    "        \n",
    "    #combine sheet with other sheets \n",
    "    print('Data shape for current sheet:\\n', sheet_data.shape, '\\n')\n",
    "    if data_visit_mean.shape[0] < 1:\n",
    "        data_visit_mean = sheet_data\n",
    "    else:\n",
    "        data_visit_mean = pd.merge(data_visit_mean, sheet_data, how='left', on=['TBIID', 'VisitSeq'], sort=False)\n",
    "        \n",
    "    print('Data shape for current final dataframe:\\n', data_visit_mean.shape, '\\n')\n",
    "\n",
    "#add group column \n",
    "data_visit_mean['Group'] = [TBIID[0] for TBIID in data_visit_mean['TBIID']]\n",
    "\n",
    "print('Final shape of data_visit_mean:\\n', data_visit_mean.shape)\n",
    "data_visit_mean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combine sheets and use mean for sheets with multiple visits per sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#some sheets have multiple visits per visit sequence and some sheets have a single visit for each visit sequence\n",
    "#we are currently interested in data only from the first visit of each visit sequence\n",
    "\n",
    "first_visits = pd.DataFrame()\n",
    "\n",
    "#each data set uses as different column name for visit date, use a dictionary to access corresponding date column name\n",
    "sheet_dic = {'single': 'ScreenDate', \n",
    "             'mult': 'MeasureDate',\n",
    "             'TBI': 'NSIFormDate',\n",
    "             'Qfup': 'ScreenDate',   \n",
    "             'DTI': 'ScreenDate', \n",
    "             'PET': 'ScreenDate',\n",
    "             'labs': 'CLabDate'}\n",
    "\n",
    "for sheet in whole_file.sheet_names:\n",
    "    \n",
    "    sheet_data_int = pd.DataFrame()\n",
    "    \n",
    "    print('Sheet being processed:\\n', sheet)\n",
    "    \n",
    "    #create intermediate dataframe\n",
    "    data_int = pd.DataFrame(data = pd.read_excel(whole_file, sheet))\n",
    "\n",
    "    #select only TBIID C and T (control and TBI)\n",
    "    data_int = data_int[data_int['TBIID'].str.match(r'[CT]\\d\\d')]\n",
    "    print('Data shape only deployed controls and mTBI groups:\\n', data_int.shape)\n",
    "\n",
    "    #meta data\n",
    "    visit_sequences = data_int['VisitSeq'].unique()\n",
    "    print('Number of visit sequences:\\n', len(visit_sequences))\n",
    "    \n",
    "    #meta data\n",
    "    participants_total = data_int['TBIID'].unique()\n",
    "    print('Number of participants:\\n', len(participants_total), '\\n')\n",
    "    \n",
    "    #for each visit\n",
    "    for visit in visit_sequences:\n",
    "        print('Visit sequence being processed:\\n', visit)\n",
    "        \n",
    "        #get visit data\n",
    "        full_visit_seq_data = data_int[data_int['VisitSeq'] == visit]\n",
    "        visit_data_int = pd.DataFrame()\n",
    "        \n",
    "        #loop through participants and for each one find and save the first visit of that visit sequence\n",
    "        participants_visit = full_visit_seq_data['TBIID'].unique()\n",
    "        #print('Number of participants for this visit sequence:\\n', len(participants_visit))\n",
    "        for part in participants_visit:\n",
    "            dates = full_visit_seq_data.loc[(full_visit_seq_data['TBIID'] == part), sheet_dic[sheet]].values\n",
    "            min_date = dates.min()\n",
    "    \n",
    "            visit_seq_data_indiv = full_visit_seq_data[(full_visit_seq_data['TBIID'] == part) & (full_visit_seq_data[sheet_dic[sheet]] == min_date)]\n",
    "            visit_data_int = visit_data_int.append(visit_seq_data_indiv)\n",
    "\n",
    "        #reset indexes and clean up missing values\n",
    "        visit_data_int = visit_data_int.reset_index(drop=True)\n",
    "        visit_data_int = visit_data_int.replace({-999.0: np.nan, 999: np.nan, 'None': np.nan})\n",
    "        \n",
    "        if sheet_data_int.shape[0] < 1:\n",
    "            sheet_data_int = visit_data_int\n",
    "        else:\n",
    "            sheet_data_int = sheet_data_int.append(visit_data_int)\n",
    " \n",
    "    #combine into one final df that contains all first visit for each sequence\n",
    "    if first_visits.shape[0] < 1:\n",
    "        first_visits = sheet_data_int\n",
    "    else:\n",
    "        first_visits = pd.merge(first_visits, sheet_data_int, how='left', on=['TBIID', 'VisitSeq'], sort=False)\n",
    "    print('Visit data shape for current sheet:\\n', first_visits.shape, '\\n')\n",
    "\n",
    "#clean up duplicates\n",
    "first_visits.drop_duplicates(inplace=True)\n",
    "\n",
    "#add group column \n",
    "first_visits['Group'] = [TBIID[0] for TBIID in first_visits['TBIID']]\n",
    "\n",
    "print('Final shape of first visit data:\\n', first_visits.shape)\n",
    "first_visits.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final = data_visit_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add in RH data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in data from RH pull and combine with df\n",
    "path_RH = 'C:/Users/Schindler/Documents/Schindler_Lab/Data/Clinical projects/PeskindTBI/RHdatapull/RHpull.csv'\n",
    "\n",
    "data_RH = pd.read_csv(path_RH)\n",
    "data_RH = pd.DataFrame(data = data_RH)\n",
    "print('Data shape all groups:\\n', data_RH.shape)\n",
    "\n",
    "#select only TBIID C and T (control and TBI)\n",
    "data_RH = data_RH[data_RH['TBIID'].str.match(r'[CT]\\d\\d')]\n",
    "print('Data shape only deployed controls and mTBI groups:\\n', data_RH.shape)\n",
    "\n",
    "#clean up missing values\n",
    "data_RH = data_RH.replace({-999.0: np.nan, 'None': np.nan})\n",
    "\n",
    "#change DA = 0 to np.nan, add ratio cals\n",
    "data_RH['DA'] = data_RH['DA'].replace({0: np.nan})\n",
    "data_RH['da_dopa_ratio'] = data_RH['DA'] / data_RH['DOPA']\n",
    "data_RH['dopac_da_ratio'] = data_RH['DOPAC'] / data_RH['DA']\n",
    "data_RH['ne_dopa_ratio'] = data_RH['NE'] / data_RH['DOPA']\n",
    "data_RH['dhpg_ne_ratio'] = data_RH['DHPG'] / data_RH['NE']\n",
    "\n",
    "#add to df containing first visit info\n",
    "data_final = pd.merge(data_final, data_RH, how='left', on=['TBIID', 'VisitSeq'], sort=False)\n",
    "\n",
    "print('Final shape of first visit data:\\n', data_final.shape)\n",
    "data_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add in MESO data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in data from MSD multiplex on blood and CSF and combine with df\n",
    "path_MESO = 'C:/Users/Schindler/Documents/Schindler_Lab/Data/Clinical projects/PeskindTBI/MSD_for_Abbie.xlsx'\n",
    "\n",
    "data_MESO = pd.read_excel(path_MESO)\n",
    "data_MESO = pd.DataFrame(data = data_MESO)\n",
    "print('Data shape all groups:\\n', data_MESO.shape)\n",
    "\n",
    "#drop participants that have no data\n",
    "data_MESO.dropna(axis=0, thresh=3, inplace=True)\n",
    "print('Data shape all groups:\\n', data_MESO.shape)\n",
    "#drop analytes that have many missing values (suggests sensitivity of MSD not sufficient for this analyte)\n",
    "data_MESO.dropna(axis=1, thresh=100, inplace=True)\n",
    "print('Data shape all groups:\\n', data_MESO.shape)\n",
    "\n",
    "#add to df containing first visit info\n",
    "data_final = pd.merge(data_final, data_MESO, how='left', on=['TBIID', 'VisitSeq'], sort=False)\n",
    "\n",
    "print('Final shape of first visit data:\\n', data_final.shape)\n",
    "data_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compute subscales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new column for sum of distance from blast (worst 5)\n",
    "data_final['QEDist_sum'] = data_final.loc[:, 'QEDist1':'QEDist5'].sum(axis=1)\n",
    "#create new column for mean of distance from blast (worst 5)\n",
    "data_final['QEDist_mean'] = data_final.loc[:, 'QEDist1':'QEDist5'].mean(axis=1)\n",
    "#create new column for min of distance from blast (worst 5)\n",
    "data_final['QEDist_min'] = data_final.loc[:, 'QEDist1':'QEDist5'].min(axis=1)\n",
    "\n",
    "#create new columns for NSI 4-factor scoring approach\n",
    "NSI_comp_vestibular = ['tbiDizzy', 'tbiBalan', 'tbiCoord']\n",
    "NSI_comp_somatosensory = ['tbiHeada', 'tbiNaus', 'tbiVision', 'tbiLight', 'tbiNoise', 'tbiTingl', 'tbiTstsml']\n",
    "NSI_comp_cognitive = ['tbiConc', 'tbiForget', 'tbiDecis', 'tbiSlow']\n",
    "NSI_comp_affective = ['tbiEnergy', 'tbiSleep', 'tbiAnx', 'tbiSad', 'tbiIrrit', 'tbiOverw']\n",
    "NSI_comp_ERP_affective = ['tbiDisin', 'tbiWithd', 'tbiMoods', 'tbiFight']\n",
    "NIS_comp_ERP_vestsom = ['tbiRing', 'tbiSpch']\n",
    "\n",
    "data_final['NSI_vestibular'] = data_final.loc[:, NSI_comp_vestibular].mean(axis=1)\n",
    "data_final['NSI_somatosensory'] = data_final.loc[:, NSI_comp_somatosensory].mean(axis=1)\n",
    "data_final['NSI_cognitive'] = data_final.loc[:, NSI_comp_cognitive].mean(axis=1)\n",
    "data_final['NSI_affective'] = data_final.loc[:, NSI_comp_affective].mean(axis=1)\n",
    "data_final['NSI_ERP_affective'] = data_final.loc[:, NSI_comp_ERP_affective].mean(axis=1)\n",
    "data_final['NIS_ERP_vestsom'] = data_final.loc[:, NIS_comp_ERP_vestsom].mean(axis=1)\n",
    "\n",
    "#create new columns for PCL subscores for 4 factor model from King et al., 1998\n",
    "PCL_reexp = ['PCL1', 'PCL2', 'PCL3', 'PCL4', 'PCL5']\n",
    "PCL_avoid = ['PCL6', 'PCL7']\n",
    "PCL_numb = ['PCL8', 'PCL9', 'PCL10', 'PCL11', 'PCL12']\n",
    "PCL_hyper = ['PCL13', 'PCL14', 'PCL15', 'PCL16', 'PCL17']\n",
    "\n",
    "data_final['PCL_reexp'] = data_final.loc[:, PCL_reexp].mean(axis=1)\n",
    "data_final['PCL_avoid'] = data_final.loc[:, PCL_avoid].mean(axis=1)\n",
    "data_final['PCL_numb'] = data_final.loc[:, PCL_numb].mean(axis=1)\n",
    "data_final['PCL_hyper'] = data_final.loc[:, PCL_hyper].mean(axis=1)\n",
    "\n",
    "#create new columns for PHQ-9 subscores for 2 factor model\n",
    "PHQ_psych = ['PHQ1', 'PHQ2', 'PHQ6', 'PHQ9']\n",
    "PHQ_somatic = [ 'PHQ3', 'PHQ4', 'PHQ5', 'PHQ7', 'PHQ8'] \n",
    "\n",
    "data_final['PHQ_psych'] = data_final.loc[:, PHQ_psych].mean(axis=1)\n",
    "data_final['PHQ_somatic'] = data_final.loc[:, PHQ_somatic].mean(axis=1)\n",
    "        \n",
    "print(data_final.shape)\n",
    "data_final.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compute health metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create bins\n",
    "BMI_bin = []\n",
    "for value in data_final['BMI'].values:\n",
    "    if value <= 20:\n",
    "        BMI_bin.append(20)\n",
    "    elif 20 <= value <= 25:\n",
    "        BMI_bin.append(25)\n",
    "    elif 25 <= value <= 30:\n",
    "        BMI_bin.append(30)\n",
    "    elif 30 <= value <= 35:\n",
    "        BMI_bin.append(35)\n",
    "    elif value >= 35:\n",
    "        BMI_bin.append(40)\n",
    "    else: \n",
    "        BMI_bin.append(np.nan)\n",
    "\n",
    "print(len(BMI_bin))\n",
    "data_final['BMI_bin'] = BMI_bin\n",
    "print(data_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cholesterol related measures \n",
    "data_final['Total_HDL_ratio'] = data_final['TotalChol'] / data_final['HDL']\n",
    "data_final['HDL_LDL_ratio'] = data_final['HDL'] / data_final['LDL']\n",
    "data_final['LDL_HDL_ratio'] = data_final['LDL'] / data_final['HDL']\n",
    "data_final['Tri_HDL_ratio'] = data_final['Trig'] / data_final['HDL']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final.to_csv('data_final.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
