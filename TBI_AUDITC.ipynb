{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting and working with data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import datetime as dt\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer, LabelEncoder, PolynomialFeatures\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GroupKFold, train_test_split, cross_val_score, cross_val_predict, GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.cluster import silhouette_score\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC  \n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import auc, accuracy_score, confusion_matrix, mean_squared_error, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "\n",
    "#visualizing results\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#import yellowbrick as yb\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path for excel sheet of multi measurements (multiple entries for each participant)\n",
    "path_multi = 'C:/Users/Schindler/Documents/Schindler_Lab/Data/Clinical projects/PeskindTBI/Individual_sheets/Multi_measurements.xlsx'\n",
    "\n",
    "#path for excel sheet of single measurements (single entry for each participant)\n",
    "path_single = 'C:/Users/Schindler/Documents/Schindler_Lab/Data/Clinical projects/PeskindTBI/Individual_sheets/Single_measurements.xlsx'\n",
    "\n",
    "#path for excel sheet of TBI measurements (single entry for each participant)\n",
    "path_TBI = 'C:/Users/Schindler/Documents/Schindler_Lab/Data/Clinical projects/PeskindTBI/Individual_sheets/TBI_symptoms.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#we are going to deal with path_multi first\n",
    "data_mult = pd.read_excel(path_multi)\n",
    "data_mult = pd.DataFrame(data = data_mult)\n",
    "print('Data shape all groups:\\n', data_mult.shape, '\\n')\n",
    "\n",
    "#select only TBIID C and T (control and TBI)\n",
    "data_mult = data_mult[data_mult['TBIID'].str.match(r'[CT]\\d\\d')]\n",
    "print('Data shape only deployed controls and mTBI groups:\\n', data_mult.shape, '\\n')\n",
    "print('Data types:\\n', data_mult.info(), '\\n')\n",
    "data_mult.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create two new data frames: 1 of the first visit record and 1 of the last visit record (based on 'MeasureDate' column)\n",
    "#add new column with group ID (C = deployed controls, T = blast mTBI)\n",
    "last_visit_data_mult = pd.DataFrame()\n",
    "first_visit_data_mult = pd.DataFrame()\n",
    "\n",
    "participants = data_mult['TBIID'].unique()\n",
    "\n",
    "for part in participants:\n",
    "    dates = data_mult.loc[data_mult['TBIID'] == part, ['MeasureDate']].values\n",
    "    max_date = dates.max()\n",
    "    min_date = dates.min()\n",
    "    \n",
    "    last_date = data_mult[(data_mult['TBIID'] == part) & (data_mult['MeasureDate'] == max_date)]\n",
    "    last_date['Group'] = part[0]\n",
    "    last_visit_data_mult = last_visit_data_mult.append(last_date)\n",
    "    \n",
    "    first_date = data_mult[(data_mult['TBIID'] == part) & (data_mult['MeasureDate'] == min_date)]\n",
    "    first_date['Group'] = part[0]\n",
    "    first_visit_data_mult = first_visit_data_mult.append(first_date)\n",
    "\n",
    "#reset indexes\n",
    "last_visit_data_mult = last_visit_data_mult.reset_index(drop=True)\n",
    "first_visit_data_mult = first_visit_data_mult.reset_index(drop=True)\n",
    "\n",
    "print(len(participants))\n",
    "print(first_visit_data_mult.shape)\n",
    "print(last_visit_data_mult.shape)\n",
    "last_visit_data_mult.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now deal with path_single\n",
    "data_single = pd.read_excel(path_single)\n",
    "data_single = pd.DataFrame(data = data_single)\n",
    "print('Data shape:\\n', data_single.shape, '\\n')\n",
    "\n",
    "#select only TBIID C and T (control and TBI)\n",
    "data_single = data_single[data_single['TBIID'].str.match(r'[CT]\\d\\d')]\n",
    "print('Data shape:\\n', data_single.shape, '\\n')\n",
    "print('Data types:\\n', data_single.info(), '\\n')\n",
    "data_single.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create two new data frames: 1 of the first visit record and 1 of the last visit record\n",
    "#add new column with group ID (C = deployed controls, T = blast mTBI)\n",
    "last_visit_data_single = pd.DataFrame()\n",
    "first_visit_data_single = pd.DataFrame()\n",
    "\n",
    "participants = data_single['TBIID'].unique()\n",
    "\n",
    "for part in participants:\n",
    "    dates = data_single.loc[data_single['TBIID'] == part, ['ScreenDate']].values\n",
    "    max_date = dates.max()\n",
    "    min_date = dates.min()\n",
    "    \n",
    "    last_date = data_single[(data_single['TBIID'] == part) & (data_single['ScreenDate'] == max_date)]\n",
    "    last_date['Group'] = part[0]\n",
    "    last_visit_data_single = last_visit_data_single.append(last_date)\n",
    "    \n",
    "    first_date = data_single[(data_single['TBIID'] == part) & (data_single['ScreenDate'] == min_date)]\n",
    "    first_date['Group'] = part[0]\n",
    "    first_visit_data_single = first_visit_data_single.append(first_date)\n",
    "    \n",
    "#reset indexes\n",
    "last_visit_data_single = last_visit_data_single.reset_index(drop=True)\n",
    "first_visit_data_single = first_visit_data_single.reset_index(drop=True)\n",
    "\n",
    "print(len(participants))\n",
    "print(first_visit_data_single.shape)\n",
    "print(last_visit_data_single.shape)\n",
    "last_visit_data_single.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#now deal with path_TBI\n",
    "data_TBI = pd.read_excel(path_TBI)\n",
    "data_TBI = pd.DataFrame(data = data_TBI)\n",
    "print('Data shape all groups:\\n', data_TBI.shape, '\\n')\n",
    "\n",
    "#select only TBIID C and T (control and TBI)\n",
    "data_TBI = data_TBI[data_TBI['TBIID'].str.match(r'[CT]\\d\\d')]\n",
    "print('Data shape only deployed controls and mTBI groups:\\n', data_mult.shape, '\\n')\n",
    "print('Data types:\\n', data_TBI.info(), '\\n')\n",
    "data_TBI.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create two new data frames: 1 of the first visit record and 1 of the last visit record\n",
    "#add new column with group ID (C = deployed controls, T = blast mTBI)\n",
    "last_visit_data_TBI = pd.DataFrame()\n",
    "first_visit_data_TBI = pd.DataFrame()\n",
    "\n",
    "participants = data_TBI['TBIID'].unique()\n",
    "\n",
    "for part in participants:\n",
    "    dates = data_TBI.loc[data_TBI['TBIID'] == part, ['FormDate']].values\n",
    "    max_date = dates.max()\n",
    "    min_date = dates.min()\n",
    "    \n",
    "    last_date = data_TBI[(data_TBI['TBIID'] == part) & (data_TBI['FormDate'] == max_date)]\n",
    "    last_date['Group'] = part[0]\n",
    "    last_visit_data_TBI = last_visit_data_TBI.append(last_date)\n",
    "    \n",
    "    first_date = data_TBI[(data_TBI['TBIID'] == part) & (data_TBI['FormDate'] == min_date)]\n",
    "    first_date['Group'] = part[0]\n",
    "    first_visit_data_TBI = first_visit_data_TBI.append(first_date)\n",
    "    \n",
    "#reset indexes\n",
    "last_visit_data_TBI = last_visit_data_TBI.reset_index(drop=True)\n",
    "first_visit_data_TBI = first_visit_data_TBI.reset_index(drop=True)\n",
    "\n",
    "print(len(participants))\n",
    "print(first_visit_data_TBI.shape)\n",
    "print(last_visit_data_TBI.shape)\n",
    "last_visit_data_TBI.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confirm the two data tables share a common key at TBIID\n",
    "print('The length of the multi data table is: ', len(last_visit_data_mult))\n",
    "print('The length of the single data table is: ', len(last_visit_data_single))\n",
    "print('The length of the TBI data table is: ', len(last_visit_data_TBI))\n",
    "print('The number of matching keys is: ', len((last_visit_data_single['TBIID'] == last_visit_data_mult['TBIID']) == True))\n",
    "print('The number of matching keys is: ', len((last_visit_data_single['TBIID'] == last_visit_data_TBI['TBIID']) == True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#joing the data sets on the common key 'TBIID'\n",
    "merge_data_last = pd.merge(last_visit_data_mult, last_visit_data_single, how='inner', on='TBIID', suffixes=('_mult', '_single'), validate='one_to_one')\n",
    "print(merge_data_last.shape)\n",
    "merge_data_last = pd.merge(merge_data_last, last_visit_data_TBI, how='inner', on='TBIID', suffixes=('_mult', '_single'), validate='one_to_one')\n",
    "print(merge_data_last.shape)\n",
    "merge_data_last.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#joing the data sets on the common key 'TBIID'\n",
    "merge_data_first = pd.merge(first_visit_data_mult, first_visit_data_single, how='inner', on='TBIID', suffixes=('_mult', '_single'), validate='one_to_one')\n",
    "print(merge_data_first.shape)\n",
    "merge_data_first = pd.merge(merge_data_first, first_visit_data_TBI, how='inner', on='TBIID', suffixes=('_mult', '_single'), validate='one_to_one')\n",
    "print(merge_data_first.shape)\n",
    "merge_data_first.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confirm the two data tables' columns were merged correctly\n",
    "print('The column length of the multi data table is: ', len(last_visit_data_mult.columns))\n",
    "print('The column length of the single data table is: ', len(last_visit_data_single.columns))\n",
    "print('The column length of the TBI data table is: ', len(last_visit_data_TBI.columns))\n",
    "print('The columns of all tables add to: ', (len(last_visit_data_mult.columns) + len(last_visit_data_single.columns) + len(last_visit_data_TBI.columns) -2))\n",
    "print('The column length of the merge data table is: ', len(merge_data_last.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confirm the two data tables' columns were merged correctly\n",
    "print('The column length of the multi data table is: ', len(first_visit_data_mult.columns))\n",
    "print('The column length of the single data table is: ', len(first_visit_data_single.columns))\n",
    "print('The column length of the TBI data table is: ', len(first_visit_data_TBI.columns))\n",
    "print('The columns of all tables add to: ', (len(first_visit_data_mult.columns) + len(first_visit_data_single.columns) + len(first_visit_data_TBI.columns) -2))\n",
    "print('The column length of the merge data table is: ', len(merge_data_first.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merge_data_first.groupby('Group_single')['auditc'].mean())\n",
    "print(merge_data_last.groupby('Group_single')['auditc'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select columns of interest and save to new df\n",
    "merge_short = merge_data_first[['TBIID', 'Group_single', 'Group_mult', 'ScreenDate_single', 'MeasureDate', 'MnthSncBlst', 'tbiDizzy', 'tbiBalan', 'tbiCoord', 'tbiHeada',\n",
    "       'tbiNaus', 'tbiVision', 'tbiLight', 'tbiHear', 'tbiNoise',\n",
    "       'tbiTingl', 'tbiTstsml', 'tbiAppet', 'tbiConc', 'tbiForget',\n",
    "       'tbiDecis', 'tbiSlow', 'tbiEnergy', 'tbiSleep', 'tbiAnx', 'tbiSad',\n",
    "       'tbiIrrit', 'tbiOverw', 'tbiDisin', 'tbiWithd', 'tbiRing',\n",
    "       'tbiMoods', 'tbiFight', 'tbiSpch', 'NSITot', 'TBITot', 'PSQIc1', 'PSQIc2', 'PSQIc3', 'PSQIc4',\n",
    "       'PSQIc5', 'PSQIc6', 'PSQIc7', 'PSQItot', 'PCLTot', 'CAPSTotal', 'PHQTot', 'auditc', 'BNITotIm', 'LEC1', 'LEC2', 'LEC3', 'LEC4', 'LEC5',\n",
    "       'LEC6', 'LEC7', 'LEC8', 'LEC9', 'LEC10', 'LEC11', 'LEC12', 'LEC13',\n",
    "    'LEC14', 'LEC15', 'LEC16', 'LEC17', 'LEC18', 'LEC19', 'LEC20',\n",
    "       'Race', 'Hispanic', 'ScreenAge', 'Education', 'cestotal', 'RivTot', 'Inhibit_Mean', 'Shift_Mean', 'Emotional Control_Mean',\n",
    "       'Self Monitor_Mean', 'Initiate_Mean', 'Working Memory_Mean',\n",
    "       'Plan/Organize_Mean', 'QLCog', 'QLCogS', 'QLBIaAns', 'QLBIaTotQ', 'QLSelf',\n",
    "       'QLSelfS', 'QLBIbAns', 'QLBIbTotQ', 'QLDaLi', 'QLDaLiS',\n",
    "       'QLBIcAns', 'QLBIcTotQ', 'QLSoc', 'QLSocS', 'QLBIdAns',\n",
    "       'QLBIdTotQ', 'QLEmot', 'QLEmotS', 'QLBIeAns', 'QLBIeTotQ',\n",
    "       'QLPhys', 'QLPhysS', 'QLBIfAns', 'QLBIfTotQ', 'WEIGHT', 'BPSYS', 'BPDIAS', 'HRATE', 'QolJob',\n",
    "       'QolDySlp', 'QolPpLon', 'QolRead', 'QolFrnd', 'QolEfTsk',\n",
    "       'QolEmCtl', 'QolLsay', 'QolConfd', 'QolPshDo', 'QolTense',\n",
    "       'QolLtDwn', 'QolMxPpl', 'QolWorn', 'QolLow', 'QolResp', 'QolAvdMx',\n",
    "       'QolBurdn', 'QolForgt', 'QolPlan', 'QolIrrit', 'Qol2Tird',\n",
    "       'QolForce', 'QolAwake', 'QolMemry', 'QKOIorA', 'QKOExpMil', 'QKOAllMil',\n",
    "       'QKOLife', 'QBlstExp', 'QDenTrx',\n",
    "       'QNoRep', 'QFrstBEMo', 'QFrstBEDay', 'QFrstBEYr', 'QRecBEMo',\n",
    "       'QRecBEDay', 'QRecBEYr', 'QNBRHT', 'APOEGen']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select columns of interest and save to new df\n",
    "merge_short_BIS = merge_data_first[['TBIID', 'Group_single', 'Group_mult', 'ScreenDate_single', 'MeasureDate', 'MnthSncBlst', 'tbiDizzy', 'tbiBalan', 'tbiCoord', 'tbiHeada',\n",
    "       'tbiNaus', 'tbiVision', 'tbiLight', 'tbiHear', 'tbiNoise',\n",
    "       'tbiTingl', 'tbiTstsml', 'tbiAppet', 'tbiConc', 'tbiForget',\n",
    "       'tbiDecis', 'tbiSlow', 'tbiEnergy', 'tbiSleep', 'tbiAnx', 'tbiSad',\n",
    "       'tbiIrrit', 'tbiOverw', 'tbiDisin', 'tbiWithd', 'tbiRing',\n",
    "       'tbiMoods', 'tbiFight', 'tbiSpch', 'NSITot', 'TBITot', 'PSQIc1', 'PSQIc2', 'PSQIc3', 'PSQIc4',\n",
    "       'PSQIc5', 'PSQIc6', 'PSQIc7', 'PSQItot', 'PCLTot', 'CAPSTotal', 'PHQTot', 'auditc', 'BNITotIm', 'LEC1', 'LEC2', 'LEC3', 'LEC4', 'LEC5',\n",
    "       'LEC6', 'LEC7', 'LEC8', 'LEC9', 'LEC10', 'LEC11', 'LEC12', 'LEC13',\n",
    "    'LEC14', 'LEC15', 'LEC16', 'LEC17', 'LEC18', 'LEC19', 'LEC20', 'BISAtt', 'BISAttAns', 'BISAttTotQ', 'BISMtr', 'BISMrtAns',\n",
    "       'BISMtrTotQ', 'BISNonpl', 'BISNonplAns', 'BISNonplTotQ', 'BISTot',\n",
    "       'BISAns', 'BISTotQ',\n",
    "       'Race', 'Hispanic', 'ScreenAge', 'Education', 'cestotal', 'RivTot', 'Inhibit_Mean', 'Shift_Mean', 'Emotional Control_Mean',\n",
    "       'Self Monitor_Mean', 'Initiate_Mean', 'Working Memory_Mean',\n",
    "       'Plan/Organize_Mean', 'QLCog', 'QLCogS', 'QLBIaAns', 'QLBIaTotQ', 'QLSelf',\n",
    "       'QLSelfS', 'QLBIbAns', 'QLBIbTotQ', 'QLDaLi', 'QLDaLiS',\n",
    "       'QLBIcAns', 'QLBIcTotQ', 'QLSoc', 'QLSocS', 'QLBIdAns',\n",
    "       'QLBIdTotQ', 'QLEmot', 'QLEmotS', 'QLBIeAns', 'QLBIeTotQ',\n",
    "       'QLPhys', 'QLPhysS', 'QLBIfAns', 'QLBIfTotQ', 'WEIGHT', 'BPSYS', 'BPDIAS', 'HRATE', 'QolJob',\n",
    "       'QolDySlp', 'QolPpLon', 'QolRead', 'QolFrnd', 'QolEfTsk',\n",
    "       'QolEmCtl', 'QolLsay', 'QolConfd', 'QolPshDo', 'QolTense',\n",
    "       'QolLtDwn', 'QolMxPpl', 'QolWorn', 'QolLow', 'QolResp', 'QolAvdMx',\n",
    "       'QolBurdn', 'QolForgt', 'QolPlan', 'QolIrrit', 'Qol2Tird',\n",
    "       'QolForce', 'QolAwake', 'QolMemry', 'QKOIorA', 'QKOExpMil', 'QKOAllMil',\n",
    "       'QKOLife', 'QBlstExp', 'QDenTrx',\n",
    "       'QNoRep', 'QFrstBEMo', 'QFrstBEDay', 'QFrstBEYr', 'QRecBEMo',\n",
    "       'QRecBEDay', 'QRecBEYr', 'QNBRHT', 'APOEGen']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-999 is a missing value so replace with 'Nan'\n",
    "merge_short = merge_short.replace({-999.0: None})\n",
    "merge_short.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_short_TBI = merge_short[merge_short['Group_single'] == 'T']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#examine missing values in each column\n",
    "print(merge_short_TBI.shape)\n",
    "merge_short_TBI.isnull().sum().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_short = merge_short.dropna(thresh=60, axis = 1)\n",
    "print(merge_short.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_short_TBI = merge_short_TBI.fillna(0)\n",
    "merge_short_TBI = merge_short_TBI.drop(87)\n",
    "merge_short_TBI.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIT_C = ['auditc']\n",
    "dep_var = ['MnthSncBlst', 'tbiDizzy', 'tbiBalan', 'tbiCoord', 'tbiHeada',\n",
    "       'tbiNaus', 'tbiVision', 'tbiLight', 'tbiHear', 'tbiNoise',\n",
    "       'tbiTingl', 'tbiTstsml', 'tbiAppet', 'tbiConc', 'tbiForget',\n",
    "       'tbiDecis', 'tbiSlow', 'tbiEnergy', 'tbiSleep', 'tbiAnx', 'tbiSad',\n",
    "       'tbiIrrit', 'tbiOverw', 'tbiDisin', 'tbiWithd', 'tbiRing',\n",
    "       'tbiMoods', 'tbiFight', 'tbiSpch', 'NSITot', 'TBITot', 'PSQIc1', 'PSQIc2', 'PSQIc3', 'PSQIc4', 'PSQIc5',\n",
    "       'PSQIc6', 'PSQIc7', 'PSQItot', 'PCLTot', 'CAPSTotal', 'PHQTot',\n",
    "       'LEC1', 'LEC2', 'LEC3', 'LEC4', 'LEC5', 'LEC6', 'LEC7',\n",
    "       'LEC8', 'LEC9', 'LEC10', 'LEC11', 'LEC12', 'LEC13', 'LEC14',\n",
    "       'LEC15', 'LEC16', 'LEC17', 'LEC18', 'LEC19', 'LEC20',\n",
    "     'ScreenAge', 'Education', 'cestotal', 'WEIGHT',\n",
    "       'BPSYS', 'BPDIAS', 'HRATE', 'QKOIorA', 'QKOExpMil', 'QKOAllMil',\n",
    "       'QKOLife', 'QBlstExp', 'QDenTrx', 'QNoRep']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(merge_short_TBI, x_vars=dep_var, y_vars=AUDIT_C, kind='reg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = merge_short_TBI[['MnthSncBlst','NSITot', 'TBITot', 'PSQIc1', 'PSQIc2', 'PSQIc3', 'PSQIc4', 'PSQIc5',\n",
    "       'PSQIc6', 'PSQIc7', 'PSQItot', 'PCLTot', 'CAPSTotal', 'PHQTot',\n",
    "     'ScreenAge', 'Education', 'cestotal', 'WEIGHT',\n",
    "       'BPSYS', 'BPDIAS', 'HRATE', 'QKOIorA', 'QKOExpMil', 'QKOAllMil',\n",
    "       'QKOLife', 'QBlstExp', 'QDenTrx', 'QNoRep',\n",
    "       'auditc']].corr()\n",
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "sns.heatmap(corr, annot=True, center=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
