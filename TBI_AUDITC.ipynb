{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting and working with data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import datetime as dt\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer, LabelEncoder, PolynomialFeatures\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GroupKFold, train_test_split, cross_val_score, cross_val_predict, GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.cluster import silhouette_score\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC  \n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import auc, accuracy_score, confusion_matrix, mean_squared_error, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "\n",
    "#visualizing results\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#import yellowbrick as yb\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (20.0, 10.0)  \n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create file paths for required data (some from TBIFreeze_190614, individual questions quiried by RCH)\n",
    "\n",
    "#path for excel sheet of multi measurements (multiple entries for each participant)\n",
    "path_multi = 'C:/Users/Schindler/Documents/Schindler_Lab/Data/Clinical projects/PeskindTBI/freeze_190614/multi.xlsx'\n",
    "\n",
    "#path for excel sheet of single measurements (single entry for each participant)\n",
    "path_single = 'C:/Users/Schindler/Documents/Schindler_Lab/Data/Clinical projects/PeskindTBI/freeze_190614/single.xlsx'\n",
    "\n",
    "#path for excel sheet of TBI measurements (single entry for each participant)\n",
    "path_TBI = 'C:/Users/Schindler/Documents/Schindler_Lab/Data/Clinical projects/PeskindTBI/freeze_190614/TBI.xlsx'\n",
    "\n",
    "#path for csv of data pulled by RCH (AUDITC individual questions, CSF monoamines)\n",
    "path_RH = 'C:/Users/Schindler/Documents/Schindler_Lab/Data/Clinical projects/PeskindTBI/RHPull.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#we are going to deal with path_multi first\n",
    "data_mult = pd.read_excel(path_multi)\n",
    "data_mult = pd.DataFrame(data = data_mult)\n",
    "print('Data shape all groups:\\n', data_mult.shape, '\\n')\n",
    "\n",
    "#select only TBIID C and T (control and TBI)\n",
    "data_mult = data_mult[data_mult['TBIID'].str.match(r'[CT]\\d\\d')]\n",
    "print('Data shape only deployed controls and mTBI groups:\\n', data_mult.shape, '\\n')\n",
    "print('Data types:\\n', data_mult.info(), '\\n')\n",
    "data_mult.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new data frame containing only the first visit record (based on 'MeasureDate' column)\n",
    "#add new column with group ID (C = deployed controls, T = blast mTBI)\n",
    "\n",
    "first_visit_data_mult = pd.DataFrame()\n",
    "\n",
    "participants = data_mult['TBIID'].unique()\n",
    "\n",
    "for part in participants:\n",
    "    dates = data_mult.loc[data_mult['TBIID'] == part, ['MeasureDate']].values\n",
    "    min_date = dates.min()\n",
    "    \n",
    "    first_date = data_mult[(data_mult['TBIID'] == part) & (data_mult['MeasureDate'] == min_date)]\n",
    "    first_date['Group'] = part[0]\n",
    "    first_visit_data_mult = first_visit_data_mult.append(first_date)\n",
    "\n",
    "#reset indexes\n",
    "first_visit_data_mult = first_visit_data_mult.reset_index(drop=True)\n",
    "\n",
    "print(len(participants))\n",
    "print(first_visit_data_mult.shape)\n",
    "first_visit_data_mult.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now deal with path_single\n",
    "data_single = pd.read_excel(path_single)\n",
    "data_single = pd.DataFrame(data = data_single)\n",
    "print('Data shape:\\n', data_single.shape, '\\n')\n",
    "\n",
    "#select only TBIID C and T (control and TBI)\n",
    "data_single = data_single[data_single['TBIID'].str.match(r'[CT]\\d\\d')]\n",
    "print('Data shape:\\n', data_single.shape, '\\n')\n",
    "print('Data types:\\n', data_single.info(), '\\n')\n",
    "data_single.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new data frame containing only the first visit record (based on 'ScreenDate' column)\n",
    "#add new column with group ID (C = deployed controls, T = blast mTBI)\n",
    "\n",
    "first_visit_data_single = pd.DataFrame()\n",
    "\n",
    "participants = data_single['TBIID'].unique()\n",
    "\n",
    "for part in participants:\n",
    "    dates = data_single.loc[data_single['TBIID'] == part, ['ScreenDate']].values\n",
    "    min_date = dates.min()\n",
    "    \n",
    "    first_date = data_single[(data_single['TBIID'] == part) & (data_single['ScreenDate'] == min_date)]\n",
    "    first_date['Group'] = part[0]\n",
    "    first_visit_data_single = first_visit_data_single.append(first_date)\n",
    "    \n",
    "#reset indexes\n",
    "first_visit_data_single = first_visit_data_single.reset_index(drop=True)\n",
    "\n",
    "print(len(participants))\n",
    "print(first_visit_data_single.shape)\n",
    "first_visit_data_single.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new column for sum of distance from blast (worst 5)\n",
    "first_visit_data_single['QEDist_sum'] = first_visit_data_single.loc[:, 'QEDist1':'QEDist5'].sum(axis=1)\n",
    "#create new column for mean of distance from blast (worst 5)\n",
    "first_visit_data_single['QEDist_mean'] = first_visit_data_single.loc[:, 'QEDist1':'QEDist5'].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#now deal with path_TBI\n",
    "data_TBI = pd.read_excel(path_TBI)\n",
    "data_TBI = pd.DataFrame(data = data_TBI)\n",
    "print('Data shape all groups:\\n', data_TBI.shape, '\\n')\n",
    "\n",
    "#select only TBIID C and T (control and TBI)\n",
    "data_TBI = data_TBI[data_TBI['TBIID'].str.match(r'[CT]\\d\\d')]\n",
    "print('Data shape only deployed controls and mTBI groups:\\n', data_TBI.shape, '\\n')\n",
    "print('Data types:\\n', data_TBI.info(), '\\n')\n",
    "data_TBI.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new data frame containing only the first visit record (based on 'NSIFormDate' column)\n",
    "#add new column with group ID (C = deployed controls, T = blast mTBI)\n",
    "\n",
    "first_visit_data_TBI = pd.DataFrame()\n",
    "\n",
    "participants = data_TBI['TBIID'].unique()\n",
    "\n",
    "for part in participants:\n",
    "    dates = data_TBI.loc[data_TBI['TBIID'] == part, ['NSIFormDate']].values\n",
    "    min_date = dates.min()\n",
    "    \n",
    "    first_date = data_TBI[(data_TBI['TBIID'] == part) & (data_TBI['NSIFormDate'] == min_date)]\n",
    "    first_date['Group'] = part[0]\n",
    "    first_visit_data_TBI = first_visit_data_TBI.append(first_date)\n",
    "    \n",
    "#reset indexes\n",
    "first_visit_data_TBI = first_visit_data_TBI.reset_index(drop=True)\n",
    "\n",
    "print(len(participants))\n",
    "print(first_visit_data_TBI.shape)\n",
    "first_visit_data_TBI.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#now deal with path_RH\n",
    "data_RH = pd.read_csv(path_RH)\n",
    "data_RH = pd.DataFrame(data = data_RH)\n",
    "print('Data shape all groups:\\n', data_RH.shape, '\\n')\n",
    "\n",
    "#select only TBIID C and T (control and TBI)\n",
    "data_RH = data_RH[data_RH['TBIID'].str.match(r'[CT]\\d\\d')]\n",
    "print('Data shape only deployed controls and mTBI groups:\\n', data_RH.shape, '\\n')\n",
    "print('Data types:\\n', data_RH.info(), '\\n')\n",
    "data_RH.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#further clean dataframe: only keep columns of interest and required metadata\n",
    "first_visit_data_mult = first_visit_data_mult[['TBIID', 'Group', 'VisitSeq', 'MeasureDate', 'hrslp', 'PSQItot',\n",
    "       'PCLTot', 'PHQTot', 'auditc', 'BNITotIm']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#further clean dataframe: only keep columns of interest and required metadata\n",
    "first_visit_data_single = first_visit_data_single[['TBIID', 'VisitSeq', \n",
    "        'ScreenDate', 'GType', 'Race', 'Hispanic', 'Handedness',\n",
    "       'ScreenAge', 'Education', 'cestotal', 'PsyEduc', 'QKOIorA', 'QKOExpMil', 'QKOAllMil',\n",
    "       'QKOLife', 'QBlstExp', 'QBEACRM', 'MnthSncBlst', 'QEDist_sum', 'QEDist_mean',\n",
    "       'BISAtt', 'BISMtr', 'BISNonpl', 'BISTot', 'DvpVers', 'DvpHA',\n",
    "       'DvpHAAct', 'DvpHASlp', 'DvpHAMd', 'DvpHAStr', 'DvpBP', 'DvpBPAct',\n",
    "       'DvpBPslp', 'DvpBPMd', 'DvpBPStr', 'CAPSTotal']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#further clean dataframe: only keep columns of interest and required metadata\n",
    "first_visit_data_TBI = first_visit_data_TBI[['TBIID', 'VisitSeq', 'NSIFormDate',\n",
    "                                             'tbiDizzy', 'tbiBalan', 'tbiCoord',\n",
    "       'tbiHeada', 'tbiNaus', 'tbiVision', 'tbiLight', 'tbiHear',\n",
    "       'tbiNoise', 'tbiTingl', 'tbiTstsml', 'tbiAppet', 'tbiConc',\n",
    "       'tbiForget', 'tbiDecis', 'tbiSlow', 'tbiEnergy', 'tbiSleep',\n",
    "       'tbiAnx', 'tbiSad', 'tbiIrrit', 'tbiOverw', 'tbiDisin', 'tbiWithd',\n",
    "       'tbiRing', 'tbiMoods', 'tbiFight', 'tbiSpch', 'NSITot', 'TBITot']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#further clean dataframe: only keep columns of interest and required metadata\n",
    "data_RH = data_RH[['TBIID', 'AUDIT1', 'AUDIT2', 'AUDIT3', 'AUDITtot',\n",
    "       'PTSD_YN', 'DA', 'DOPA', 'NE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#now deal with path_PET\n",
    "data_PET = pd.read_excel(path_PET)\n",
    "data_PET = pd.DataFrame(data = data_PET)\n",
    "print('Data shape all groups:\\n', data_PET.shape, '\\n')\n",
    "\n",
    "#select only TBIID C and T (control and TBI)\n",
    "data_PET = data_PET[data_PET['TBIID'].str.match(r'[CT]\\d\\d')]\n",
    "print('Data shape only deployed controls and mTBI groups:\\n', data_PET.shape, '\\n')\n",
    "print('Data types:\\n', data_PET.info(), '\\n')\n",
    "data_PET.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new data frame containing only the first visit record (based on 'ScreenDate' column)\n",
    "#add new column with group ID (C = deployed controls, T = blast mTBI)\n",
    "\n",
    "first_visit_data_PET = pd.DataFrame()\n",
    "\n",
    "participants = data_PET['TBIID'].unique()\n",
    "\n",
    "for part in participants:\n",
    "    dates = data_PET.loc[data_PET['TBIID'] == part, ['ScreenDate']].values\n",
    "    min_date = dates.min()\n",
    "    \n",
    "    first_date = data_PET[(data_PET['TBIID'] == part) & (data_PET['ScreenDate'] == min_date)]\n",
    "    first_date['Group'] = part[0]\n",
    "    first_visit_data_PET = first_visit_data_PET.append(first_date)\n",
    "    \n",
    "#reset indexes\n",
    "first_visit_data_PET = first_visit_data_PET.reset_index(drop=True)\n",
    "\n",
    "print(len(participants))\n",
    "print(first_visit_data_PET.shape)\n",
    "first_visit_data_PET.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check length of data tables (AUDITC has more entries)\n",
    "print('The length of the multi data table is: ', first_visit_data_mult.shape)\n",
    "print('The length of the single data table is: ', first_visit_data_single.shape)\n",
    "print('The length of the TBI data table is: ', first_visit_data_TBI.shape)\n",
    "print('The length of the RH data table is: ', data_RH.shape)\n",
    "#print('The length of the TBI data table is: ', len(first_visit_data_PET))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#joing the data sets on the common key 'TBIID' - this should only keep entries that are shared across all data sets\n",
    "merge_data_first = pd.merge(first_visit_data_mult, first_visit_data_single, how='inner', on='TBIID', suffixes=('_mult', '_single'), validate='one_to_one')\n",
    "print(merge_data_first.shape)\n",
    "merge_data_first = pd.merge(merge_data_first, first_visit_data_TBI, how='inner', on='TBIID', suffixes=('_mult', '_TBI'), validate='one_to_one')\n",
    "print(merge_data_first.shape)\n",
    "#merge_data_first = pd.merge(merge_data_first, first_visit_data_PET, how='inner', on='TBIID', suffixes=('_mult', '_PET'), validate='one_to_one')\n",
    "#print(merge_data_first.shape)\n",
    "merge_data_first = pd.merge(merge_data_first, data_RH, how='inner', on='TBIID', suffixes=('_mult', '_AUDITC'), validate='one_to_one')\n",
    "print(merge_data_first.shape)\n",
    "merge_data_first.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#further clean dataframe: rearange columns and only keep columns of interest and required metadata\n",
    "merge_data_first.columns = ['TBIID', 'Group', 'VisitSeq_mult', 'MeasureDate_mult', 'hrslp',\n",
    "       'PSQItot', 'PCLTot', 'PHQTot', 'auditc', 'BNITotIm',\n",
    "       'VisitSeq_single', 'MeasureDate_single', 'GType', 'Race', 'Hispanic',\n",
    "       'Handedness', 'ScreenAge', 'Education', 'cestotal', 'PsyEduc',\n",
    "       'QKOIorA', 'QKOExpMil', 'QKOAllMil', 'QKOLife', 'QBlstExp',\n",
    "       'QBEACRM', 'MnthSncBlst', 'QEDist_sum', 'QEDist_mean', 'BISAtt',\n",
    "       'BISMtr', 'BISNonpl', 'BISTot', 'DvpVers', 'DvpHA', 'DvpHAAct',\n",
    "       'DvpHASlp', 'DvpHAMd', 'DvpHAStr', 'DvpBP', 'DvpBPAct', 'DvpBPslp',\n",
    "       'DvpBPMd', 'DvpBPStr', \n",
    "       'CAPSTotal', 'VisitSeq_TBI', 'MeasureDate_TBI', 'tbiDizzy', 'tbiBalan',\n",
    "       'tbiCoord', 'tbiHeada', 'tbiNaus', 'tbiVision', 'tbiLight',\n",
    "       'tbiHear', 'tbiNoise', 'tbiTingl', 'tbiTstsml', 'tbiAppet',\n",
    "       'tbiConc', 'tbiForget', 'tbiDecis', 'tbiSlow', 'tbiEnergy',\n",
    "       'tbiSleep', 'tbiAnx', 'tbiSad', 'tbiIrrit', 'tbiOverw', 'tbiDisin',\n",
    "       'tbiWithd', 'tbiRing', 'tbiMoods', 'tbiFight', 'tbiSpch', 'NSITot',\n",
    "       'TBITot', 'AUDIT1', 'AUDIT2',\n",
    "       'AUDIT3', 'AUDITtot', 'PTSD_YN', 'DA', 'DOPA', 'NE']\n",
    "\n",
    "merge_data_first = merge_data_first[['TBIID', 'Group', 'VisitSeq_mult', 'VisitSeq_single', 'VisitSeq_TBI',\n",
    "                                     'MeasureDate_mult', 'MeasureDate_single', 'MeasureDate_TBI',\n",
    "                                     'GType', 'Race', 'Hispanic', 'Handedness', 'ScreenAge', 'Education', \n",
    "                                     'cestotal', 'MnthSncBlst', 'QEDist_sum', 'QEDist_mean', 'NSITot', 'TBITot',\n",
    "                                     'hrslp', 'PSQItot', 'PCLTot', 'CAPSTotal', 'PHQTot', 'PTSD_YN', 'BNITotIm',\n",
    "                                     'auditc', 'AUDITtot', 'AUDIT1', 'AUDIT2', 'AUDIT3',  \n",
    "                                     'DA', 'DOPA', 'NE',  \n",
    "                                     'QKOIorA', 'QKOExpMil', 'QKOAllMil', 'QKOLife', 'QBlstExp', 'QBEACRM', \n",
    "                                     'BISAtt', 'BISMtr', 'BISNonpl', 'BISTot', \n",
    "                                     'DvpVers', 'DvpHA', 'DvpHAAct', 'DvpHASlp', 'DvpHAMd', 'DvpHAStr', 'DvpBP',\n",
    "                                     'DvpBPAct', 'DvpBPslp', 'DvpBPMd', 'DvpBPStr', \n",
    "                                     'tbiDizzy', 'tbiBalan', 'tbiCoord', 'tbiHeada', 'tbiNaus', 'tbiVision', 'tbiLight',\n",
    "                                     'tbiHear', 'tbiNoise', 'tbiTingl', 'tbiTstsml', 'tbiAppet',\n",
    "                                     'tbiConc', 'tbiForget', 'tbiDecis', 'tbiSlow', 'tbiEnergy',\n",
    "                                     'tbiSleep', 'tbiAnx', 'tbiSad', 'tbiIrrit', 'tbiOverw', 'tbiDisin',\n",
    "                                     'tbiWithd', 'tbiRing', 'tbiMoods', 'tbiFight', 'tbiSpch']]\n",
    "\n",
    "print(merge_data_first.shape)\n",
    "merge_data_first.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-999 and 'None' are missing values so replace with 'Nan'\n",
    "merge_data_first = merge_data_first.replace({-999.0: np.nan, 'None': np.nan})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#explore missing data\n",
    "print(merge_data_first.shape)\n",
    "print(merge_data_first[merge_data_first['Group'] == 'T'].shape)\n",
    "print(merge_data_first[merge_data_first['Group'] == 'T'].isna().sum().sort_values(ascending=False))\n",
    "merge_data_first[merge_data_first['Group'] == 'T'].isna().sum().sort_values(ascending=False).plot(kind = 'hist')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_vars = ['Hispanic', 'Handedness',\n",
    "       'ScreenAge', 'Education', 'cestotal', 'MnthSncBlst', 'QEDist_sum',\n",
    "       'QEDist_mean', 'NSITot', 'TBITot', 'hrslp', 'PSQItot', 'PCLTot',\n",
    "       'CAPSTotal', 'PHQTot', 'PTSD_YN', 'BNITotIm', 'auditc', 'AUDITtot',\n",
    "       'AUDIT1', 'AUDIT2', 'AUDIT3', 'DA', 'DOPA', 'NE', 'QKOIorA',\n",
    "       'QKOExpMil', 'QKOAllMil', 'QKOLife', 'QBlstExp', 'QBEACRM',\n",
    "       'BISAtt', 'BISMtr', 'BISNonpl', 'BISTot', 'DvpVers', 'DvpHA',\n",
    "       'DvpHAAct', 'DvpHASlp', 'DvpHAMd', 'DvpHAStr', 'DvpBP', 'DvpBPAct',\n",
    "       'DvpBPslp', 'DvpBPMd', 'DvpBPStr', 'tbiDizzy', 'tbiBalan',\n",
    "       'tbiCoord', 'tbiHeada', 'tbiNaus', 'tbiVision', 'tbiLight',\n",
    "       'tbiHear', 'tbiNoise', 'tbiTingl', 'tbiTstsml', 'tbiAppet',\n",
    "       'tbiConc', 'tbiForget', 'tbiDecis', 'tbiSlow', 'tbiEnergy',\n",
    "       'tbiSleep', 'tbiAnx', 'tbiSad', 'tbiIrrit', 'tbiOverw', 'tbiDisin',\n",
    "       'tbiWithd', 'tbiRing', 'tbiMoods', 'tbiFight', 'tbiSpch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in dep_vars:\n",
    "    print(param)\n",
    "    plt.figure(figsize=(10,5))\n",
    "    try:\n",
    "        merge_data_first.groupby(['Group'])[param].mean().plot(kind='bar', yerr=merge_data_first.groupby(['Group'])[param].sem())\n",
    "        plt.ylabel([param])\n",
    "    #plt.savefig(str(param + '.png'))\n",
    "        plt.show()\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = merge_data_first.groupby('Group').corr()\n",
    "fig, ax = plt.subplots(figsize=(40, 40))\n",
    "sns.heatmap(corr, center=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDITC_cols = ['AUDITtot',\n",
    "       'AUDIT1', 'AUDIT2', 'AUDIT3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in dep_vars:\n",
    "    print(param)\n",
    "    plt.figure(figsize=(10,5))\n",
    "    try:\n",
    "        #merge_data_first.groupby(['Group'])[param].mean().plot(kind='bar', yerr=merge_data_first.groupby(['Group'])[param].sem())\n",
    "        \n",
    "        sns.pairplot(merge_data_first, x_vars=param, y_vars=AUDITC_cols, kind='reg', hue='Group', dropna=True)\n",
    "        \n",
    "        plt.ylabel([param])\n",
    "    #plt.savefig(str(param + '.png'))\n",
    "        plt.show()\n",
    "    except:\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corr.to_csv('corr.csv')\n",
    "merge_data_first.to_csv('merge_data_first.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_data_first = merge_data_first[merge_data_first[\"TBIID\"] != 'C010']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIT_tot_counts = merge_data_first.groupby('Group')['AUDITtot'].value_counts()\n",
    "AUDIT_1_counts = merge_data_first.groupby('Group')['AUDIT1'].value_counts()\n",
    "AUDIT_2_counts = merge_data_first.groupby('Group')['AUDIT2'].value_counts()\n",
    "AUDIT_3_counts = merge_data_first.groupby('Group')['AUDIT3'].value_counts()\n",
    "AUDIT_tot_counts.to_csv('AUDIT_tot_counts.csv')\n",
    "AUDIT_1_counts.to_csv('AUDIT_1_counts.csv')\n",
    "AUDIT_2_counts.to_csv('AUDIT_2_counts.csv')\n",
    "AUDIT_3_counts.to_csv('AUDIT_3_counts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIT_tot_perc = merge_data_first.groupby('Group')['AUDITtot'].value_counts() / merge_data_first.groupby('Group')['AUDITtot'].count()\n",
    "AUDIT_1_perc = merge_data_first.groupby('Group')['AUDIT1'].value_counts() / merge_data_first.groupby('Group')['AUDIT1'].count()\n",
    "AUDIT_2_perc = merge_data_first.groupby('Group')['AUDIT2'].value_counts() / merge_data_first.groupby('Group')['AUDIT2'].count()\n",
    "AUDIT_3_perc = merge_data_first.groupby('Group')['AUDIT3'].value_counts() / merge_data_first.groupby('Group')['AUDIT3'].count()\n",
    "AUDIT_tot_perc.to_csv('AUDIT_tot_perc.csv')\n",
    "AUDIT_1_perc.to_csv('AUDIT_1_perc.csv')\n",
    "AUDIT_2_perc.to_csv('AUDIT_2_perc.csv')\n",
    "AUDIT_3_perc.to_csv('AUDIT_3_perc.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
