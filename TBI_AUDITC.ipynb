{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting and working with data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import datetime as dt\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer, LabelEncoder, PolynomialFeatures\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GroupKFold, train_test_split, cross_val_score, cross_val_predict, GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.cluster import silhouette_score\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC  \n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import auc, accuracy_score, confusion_matrix, mean_squared_error, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "\n",
    "#visualizing results\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#import yellowbrick as yb\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (20.0, 10.0)  \n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create file paths for required data (some from TBIFreeze_20190215, individual questions quiried by RCH)\n",
    "\n",
    "#path for AUDITC individual questions\n",
    "AUDITC_path = 'C:/Users/Schindler/Documents/Schindler_Lab/Data/Clinical projects/PeskindTBI/AUDITC/auditDataSet_Oct2018_smaller.csv'\n",
    "\n",
    "#path for excel sheet of multi measurements (multiple entries for each participant)\n",
    "path_multi = 'C:/Users/Schindler/Documents/Schindler_Lab/Data/Clinical projects/PeskindTBI/Individual_sheets/Multi_measurements.xlsx'\n",
    "\n",
    "#path for excel sheet of single measurements (single entry for each participant)\n",
    "path_single = 'C:/Users/Schindler/Documents/Schindler_Lab/Data/Clinical projects/PeskindTBI/Individual_sheets/Single_measurements.xlsx'\n",
    "\n",
    "#path for excel sheet of TBI measurements (single entry for each participant)\n",
    "path_TBI = 'C:/Users/Schindler/Documents/Schindler_Lab/Data/Clinical projects/PeskindTBI/Individual_sheets/TBI_symptoms.xlsx'\n",
    "\n",
    "#path for excel sheet of TBI measurements (single entry for each participant)\n",
    "path_PET = 'C:/Users/Schindler/Documents/Schindler_Lab/Data/Clinical projects/PeskindTBI/Individual_sheets/FDG_PET.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#we are going to deal with path_multi first\n",
    "data_mult = pd.read_excel(path_multi)\n",
    "data_mult = pd.DataFrame(data = data_mult)\n",
    "print('Data shape all groups:\\n', data_mult.shape, '\\n')\n",
    "\n",
    "#select only TBIID C and T (control and TBI)\n",
    "data_mult = data_mult[data_mult['TBIID'].str.match(r'[CT]\\d\\d')]\n",
    "print('Data shape only deployed controls and mTBI groups:\\n', data_mult.shape, '\\n')\n",
    "print('Data types:\\n', data_mult.info(), '\\n')\n",
    "data_mult.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new data frame containing only the first visit record (based on 'MeasureDate' column)\n",
    "#add new column with group ID (C = deployed controls, T = blast mTBI)\n",
    "\n",
    "first_visit_data_mult = pd.DataFrame()\n",
    "\n",
    "participants = data_mult['TBIID'].unique()\n",
    "\n",
    "for part in participants:\n",
    "    dates = data_mult.loc[data_mult['TBIID'] == part, ['MeasureDate']].values\n",
    "    min_date = dates.min()\n",
    "    \n",
    "    first_date = data_mult[(data_mult['TBIID'] == part) & (data_mult['MeasureDate'] == min_date)]\n",
    "    first_date['Group'] = part[0]\n",
    "    first_visit_data_mult = first_visit_data_mult.append(first_date)\n",
    "\n",
    "#reset indexes\n",
    "first_visit_data_mult = first_visit_data_mult.reset_index(drop=True)\n",
    "\n",
    "print(len(participants))\n",
    "print(first_visit_data_mult.shape)\n",
    "first_visit_data_mult.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now deal with path_single\n",
    "data_single = pd.read_excel(path_single)\n",
    "data_single = pd.DataFrame(data = data_single)\n",
    "print('Data shape:\\n', data_single.shape, '\\n')\n",
    "\n",
    "#select only TBIID C and T (control and TBI)\n",
    "data_single = data_single[data_single['TBIID'].str.match(r'[CT]\\d\\d')]\n",
    "print('Data shape:\\n', data_single.shape, '\\n')\n",
    "print('Data types:\\n', data_single.info(), '\\n')\n",
    "data_single.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new data frame containing only the first visit record (based on 'ScreenDate' column)\n",
    "#add new column with group ID (C = deployed controls, T = blast mTBI)\n",
    "\n",
    "first_visit_data_single = pd.DataFrame()\n",
    "\n",
    "participants = data_single['TBIID'].unique()\n",
    "\n",
    "for part in participants:\n",
    "    dates = data_single.loc[data_single['TBIID'] == part, ['ScreenDate']].values\n",
    "    min_date = dates.min()\n",
    "    \n",
    "    first_date = data_single[(data_single['TBIID'] == part) & (data_single['ScreenDate'] == min_date)]\n",
    "    first_date['Group'] = part[0]\n",
    "    first_visit_data_single = first_visit_data_single.append(first_date)\n",
    "    \n",
    "#reset indexes\n",
    "first_visit_data_single = first_visit_data_single.reset_index(drop=True)\n",
    "\n",
    "print(len(participants))\n",
    "print(first_visit_data_single.shape)\n",
    "first_visit_data_single.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#now deal with path_TBI\n",
    "data_TBI = pd.read_excel(path_TBI)\n",
    "data_TBI = pd.DataFrame(data = data_TBI)\n",
    "print('Data shape all groups:\\n', data_TBI.shape, '\\n')\n",
    "\n",
    "#select only TBIID C and T (control and TBI)\n",
    "data_TBI = data_TBI[data_TBI['TBIID'].str.match(r'[CT]\\d\\d')]\n",
    "print('Data shape only deployed controls and mTBI groups:\\n', data_mult.shape, '\\n')\n",
    "print('Data types:\\n', data_TBI.info(), '\\n')\n",
    "data_TBI.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new data frame containing only the first visit record (based on 'FormDate' column)\n",
    "#add new column with group ID (C = deployed controls, T = blast mTBI)\n",
    "\n",
    "first_visit_data_TBI = pd.DataFrame()\n",
    "\n",
    "participants = data_TBI['TBIID'].unique()\n",
    "\n",
    "for part in participants:\n",
    "    dates = data_TBI.loc[data_TBI['TBIID'] == part, ['FormDate']].values\n",
    "    min_date = dates.min()\n",
    "    \n",
    "    first_date = data_TBI[(data_TBI['TBIID'] == part) & (data_TBI['FormDate'] == min_date)]\n",
    "    first_date['Group'] = part[0]\n",
    "    first_visit_data_TBI = first_visit_data_TBI.append(first_date)\n",
    "    \n",
    "#reset indexes\n",
    "first_visit_data_TBI = first_visit_data_TBI.reset_index(drop=True)\n",
    "\n",
    "print(len(participants))\n",
    "print(first_visit_data_TBI.shape)\n",
    "first_visit_data_TBI.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#now deal with path_PET\n",
    "data_PET = pd.read_excel(path_PET)\n",
    "data_PET = pd.DataFrame(data = data_PET)\n",
    "print('Data shape all groups:\\n', data_PET.shape, '\\n')\n",
    "\n",
    "#select only TBIID C and T (control and TBI)\n",
    "data_PET = data_PET[data_PET['TBIID'].str.match(r'[CT]\\d\\d')]\n",
    "print('Data shape only deployed controls and mTBI groups:\\n', data_PET.shape, '\\n')\n",
    "print('Data types:\\n', data_PET.info(), '\\n')\n",
    "data_PET.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new data frame containing only the first visit record (based on 'ScreenDate' column)\n",
    "#add new column with group ID (C = deployed controls, T = blast mTBI)\n",
    "\n",
    "first_visit_data_PET = pd.DataFrame()\n",
    "\n",
    "participants = data_PET['TBIID'].unique()\n",
    "\n",
    "for part in participants:\n",
    "    dates = data_PET.loc[data_PET['TBIID'] == part, ['ScreenDate']].values\n",
    "    min_date = dates.min()\n",
    "    \n",
    "    first_date = data_PET[(data_PET['TBIID'] == part) & (data_PET['ScreenDate'] == min_date)]\n",
    "    first_date['Group'] = part[0]\n",
    "    first_visit_data_PET = first_visit_data_PET.append(first_date)\n",
    "    \n",
    "#reset indexes\n",
    "first_visit_data_PET = first_visit_data_PET.reset_index(drop=True)\n",
    "\n",
    "print(len(participants))\n",
    "print(first_visit_data_PET.shape)\n",
    "first_visit_data_PET.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#now deal with AUDITC path - only one date\n",
    "data_AUDITC = pd.read_csv(AUDITC_path)\n",
    "data_AUDITC = pd.DataFrame(data = data_AUDITC)\n",
    "print('Data shape all groups:\\n', data_AUDITC.shape, '\\n')\n",
    "\n",
    "#select only TBIID C and T (control and TBI)\n",
    "data_AUDITC = data_AUDITC[data_AUDITC['TBIID'].str.match(r'[CT]\\d\\d')]\n",
    "print('Data shape only deployed controls and mTBI groups:\\n', data_AUDITC.shape, '\\n')\n",
    "print('Data types:\\n', data_AUDITC.info(), '\\n')\n",
    "data_AUDITC.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check length of data tables (AUDITC has more entries)\n",
    "print('The length of the multi data table is: ', len(first_visit_data_mult))\n",
    "print('The length of the single data table is: ', len(first_visit_data_single))\n",
    "print('The length of the TBI data table is: ', len(first_visit_data_TBI))\n",
    "print('The length of the TBI data table is: ', len(first_visit_data_PET))\n",
    "print('The length of the AUDITC data table is: ', len(data_AUDITC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#joing the data sets on the common key 'TBIID' - this should only keep entries that are shared across all data sets\n",
    "merge_data_first = pd.merge(first_visit_data_mult, first_visit_data_single, how='inner', on='TBIID', suffixes=('_mult', '_single'), validate='one_to_one')\n",
    "print(merge_data_first.shape)\n",
    "merge_data_first = pd.merge(merge_data_first, first_visit_data_TBI, how='inner', on='TBIID', suffixes=('_mult', '_TBI'), validate='one_to_one')\n",
    "print(merge_data_first.shape)\n",
    "merge_data_first = pd.merge(merge_data_first, first_visit_data_PET, how='inner', on='TBIID', suffixes=('_mult', '_PET'), validate='one_to_one')\n",
    "print(merge_data_first.shape)\n",
    "merge_data_first = pd.merge(merge_data_first, data_AUDITC, how='inner', on='TBIID', suffixes=('_mult', '_AUDITC'), validate='one_to_one')\n",
    "print(merge_data_first.shape)\n",
    "merge_data_first.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confirm the two data tables' columns were merged correctly\n",
    "print('The column length of the multi data table is: ', len(first_visit_data_mult.columns))\n",
    "print('The column length of the single data table is: ', len(first_visit_data_single.columns))\n",
    "print('The column length of the TBI data table is: ', len(first_visit_data_TBI.columns))\n",
    "print('The column length of the TBI data table is: ', len(first_visit_data_PET.columns))\n",
    "print('The column length of the AUDITC data table is: ', len(data_AUDITC.columns))\n",
    "print('The columns of all tables add to: ', (len(first_visit_data_mult.columns) + len(first_visit_data_single.columns) + len(first_visit_data_TBI.columns) + len(first_visit_data_PET.columns) + len(data_AUDITC.columns) -4))\n",
    "print('The column length of the merge data table is: ', len(merge_data_first.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-999 and 'None' are missing values so replace with 'Nan'\n",
    "merge_data_first = merge_data_first.replace({-999.0: np.nan, 'None': np.nan})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_vars = ['Group_PET', 'DOB', 'ScreenAge', 'Education', 'servconn',\n",
    "       'cestotal', 'MnthSncBlst', 'AUDIT1', 'AUDIT2', 'AUDIT3', 'AUDITtot', 'PSQItot_AUDITC', 'PCLTot_AUDITC',\n",
    " 'CAPSTotal_AUDITC', 'PTSD_YN', 'LECTotal', 'NSITot_AUDITC', 'QKOIorA_AUDITC',\n",
    " 'QKOExpMil_AUDITC', 'QKOAllMil_AUDITC', 'QKOLife_AUDITC', 'QBlstExp_AUDITC',\n",
    " 'QBEACRM_AUDITC', 'QBEIorA_AUDITC', 'DA', 'DOPA', 'NE', 'tbiDizzy', 'tbiBalan', 'tbiCoord',\n",
    "       'tbiHeada', 'tbiNaus', 'tbiVision', 'tbiLight', 'tbiHear',\n",
    "       'tbiNoise', 'tbiTingl', 'tbiTstsml', 'tbiAppet', 'tbiConc',\n",
    "       'tbiForget', 'tbiDecis', 'tbiSlow', 'tbiEnergy', 'tbiSleep',\n",
    "       'tbiAnx', 'tbiSad', 'tbiIrrit', 'tbiOverw', 'tbiDisin', 'tbiWithd',\n",
    "       'tbiRing', 'tbiMoods', 'tbiFight', 'tbiSpch', 'NSITot_mult', 'TBITot', 'WCSTPrs', 'WCSTPrsT', 'WCSTCL',\n",
    "       'WCSTCLP', 'WCSTCLPT', 'WCSTCat', 'WCSTFail', 'Inhibit_Mean', 'Shift_Mean',\n",
    "       'Emotional Control_Mean', 'Self Monitor_Mean', 'Initiate_Mean',\n",
    "       'Working Memory_Mean', 'Plan/Organize_Mean', 'FrTotBe', 'FrTotBeT', 'FrTotBeAns', 'FrTotBeQ',\n",
    "       'FrTotAf', 'FrTotAfT', 'FrTotAfAns', 'FrTotAfQ', 'BISAtt', 'BISAttAns', 'BISAttTotQ', 'BISMtr', 'BISMrtAns',\n",
    "       'BISMtrTotQ', 'BISNonpl', 'BISNonplAns', 'BISNonplTotQ', 'BISTot',\n",
    "       'BISAns', 'BISTotQ', 'WEIGHT', 'BPSYS', 'BPDIAS', 'HRATE', 'hrslp', 'PSQI1hr', 'PSQI1min',\n",
    "       'PSQI2', 'PSQI3hr', 'PSQI3min', 'PSQI5a', 'PSQI5b', 'PSQI5c',\n",
    "       'PSQI5d', 'PSQI5e', 'PSQI5f', 'PSQI5g', 'PSQI5h', 'PSQI5i',\n",
    "       'PSQI5j', 'PSQI5jco', 'PSQI6', 'PSQI7', 'PSQI8', 'PSQI9', 'PSQIc1',\n",
    "       'PSQIc2', 'PSQIc3', 'PSQIc4', 'PSQIc5', 'PSQIc6', 'PSQIc7',\n",
    "       'PSQItot_mult', 'PCL1', 'PCL2', 'PCL3', 'PCL4', 'PCL5', 'PCL6', 'PCL7',\n",
    "       'PCL8', 'PCL9', 'PCL10', 'PCL11', 'PCL12', 'PCL13', 'PCL14',\n",
    "       'PCL15', 'PCL16', 'PCL17', 'PCLTot_mult', \n",
    "       'capsCrtA', 'CAPSTotal_mult', 'PHQ1', 'PHQ2', 'PHQ3', 'PHQ4',\n",
    "       'PHQ5', 'PHQ6', 'PHQ7', 'PHQ8', 'PHQ9', 'PHQTot', 'auditc',\n",
    "       'BNI1Im', 'BNI2Im', 'BNI3Im', 'BNI4Im', 'BNI5Im', 'BNI6Im',\n",
    "       'BNI7Im', 'BNI8Im', 'BNI9Im', 'BNI10Im', 'BNI11', 'BNITotIm',\n",
    "       'LEC1', 'LEC2', 'LEC3', 'LEC4', 'LEC5', 'LEC6', 'LEC7', 'LEC8',\n",
    "       'LEC9', 'LEC10', 'LEC11', 'LEC12', 'LEC13', 'LEC14', 'LEC15',\n",
    "       'LEC16', 'LEC17', 'LEC18', 'LEC19', 'LEC20', 'Insula_l', 'Insula_r', 'Cingulum_Ant_l',\n",
    "       'Cingulum_Ant_r', 'Cingulum_Mid_l', 'Cingulum_Mid_r',\n",
    "       'Cingulum_Post_l', 'Cingulum_Post_r', \n",
    "       'Amygdala_l', 'Amygdala_r', 'CaudateNucl_l',\n",
    "       'CaudateNucl_r', 'Putamen_l', 'Putamen_r', 'Pallidum_l',\n",
    "       'Pallidum_r', 'Midbrain', 'Pons']\n",
    "merge_data_first_dep = merge_data_first[dep_vars]\n",
    "print(merge_data_first_dep.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#explore missing data\n",
    "print(merge_data_first_dep.shape)\n",
    "merge_data_first_dep.isna().sum().sort_values(ascending=False).plot(kind = 'hist')\n",
    "plt.show()\n",
    "#drop columns with greater than 50 missing values\n",
    "merge_first_clean = merge_data_first_dep.dropna(thresh = 100, axis = 1)\n",
    "print(merge_first_clean.shape)\n",
    "print(merge_first_clean.isna().sum().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confirm data sets match\n",
    "print(merge_first_clean.groupby('Group_PET')['auditc'].mean())\n",
    "print(merge_first_clean.groupby('Group_PET')['AUDITtot'].mean())\n",
    "#vizulaize AUDIT_C data by group\n",
    "AUDIT_C_names = ['AUDIT1', 'AUDIT2', 'AUDIT3', 'AUDITtot']\n",
    "for param in AUDIT_C_names:\n",
    "    plt.figure(figsize=(10,10))\n",
    "    merge_first_clean.groupby(['Group_PET'])[param].mean().plot(kind='bar', yerr=merge_first_clean.groupby(['Group_PET'])[param].sem())\n",
    "    plt.ylabel([param])\n",
    "    #plt.savefig(str(param + '.png'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dep = ['ScreenAge', 'Education', 'servconn',\n",
    "       'cestotal', 'MnthSncBlst', 'AUDIT1', 'AUDIT2', 'AUDIT3',\n",
    "       'AUDITtot', 'PSQItot_AUDITC', 'PCLTot_AUDITC', 'CAPSTotal_AUDITC',\n",
    "       'PTSD_YN', 'LECTotal', 'NSITot_AUDITC', \n",
    "       'NSITot_mult', 'TBITot', 'QKOIorA_AUDITC',\n",
    "       'QKOExpMil_AUDITC', 'QKOAllMil_AUDITC', 'QKOLife_AUDITC',\n",
    "       'QBlstExp_AUDITC', 'QBEIorA_AUDITC', \n",
    "       'tbiSleep', 'tbiAnx', 'tbiSad', 'tbiIrrit', 'tbiOverw', 'tbiDisin',\n",
    "       'tbiWithd', 'tbiMoods', 'tbiFight', 'WEIGHT', 'BPSYS', 'BPDIAS', 'HRATE', 'hrslp',\n",
    "       'PSQItot_mult', 'PCLTot_mult', 'capsCrtA',\n",
    "       'CAPSTotal_mult', 'PHQTot', 'Amygdala_l', 'Amygdala_r',\n",
    "       'Pallidum_l', 'Pallidum_r', 'Midbrain']\n",
    "AUDIT_C_names = ['AUDIT1', 'AUDIT2', 'AUDIT3', 'AUDITtot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in all_dep:\n",
    "    plt.figure(figsize=(10,10))\n",
    "    merge_first_clean.groupby(['Group_PET'])[param].mean().plot(kind='bar', yerr=merge_first_clean.groupby(['Group_PET'])[param].sem())\n",
    "    plt.ylabel([param])\n",
    "    #plt.savefig(str(param + '.png'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = merge_first_clean[all_dep].groupby('Group_PET').corr()\n",
    "fig, ax = plt.subplots(figsize=(40, 40))\n",
    "sns.heatmap(corr, center=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(merge_first_clean[merge_first_clean['Group_PET'] == 'T'], x_vars=all_dep, y_vars=AUDIT_C_names, kind='reg', dropna=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
