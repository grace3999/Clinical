{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting and working with data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import scipy as sp\n",
    "\n",
    "#visualizing results\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_context('poster')\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from kmodes.kmodes import KModes\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "import scipy.cluster.hierarchy as shc\n",
    "\n",
    "from minisom import MiniSom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'C:/Users/Schindler/Documents/Schindler_Lab/Data/Clinical projects/PeskindTBI/final_data/data_final.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in csv containing data from all surveys and all visitseqs\n",
    "data = pd.read_csv(data_path, index_col=0)\n",
    "data = pd.DataFrame(data = data)\n",
    "\n",
    "print('Original data shape:\\n', data.shape, '\\n')\n",
    "print(data.info())\n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#determined outliers for auditc and QBlstExp (outlier = >3 SD from mean) and remove\n",
    "data = data[data[\"TBIID\"] != 'C010']\n",
    "data = data[data[\"TBIID\"] != 'T080']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUDIT-C clustering with C and T from first visit sequence\n",
    "\n",
    "- AUDIT-C answers are categorical, so does not readily apply to common cluster methods (e.g. categorical vs. continuous)\n",
    "    - although some argue that because AUDIT-C questions contain numbers (number of drinks etc.) you can use as if numerical\n",
    "- will compare three ways of expressing AUDIT-C data\n",
    "    - raw scores\n",
    "    - one hot encoded\n",
    "    - transformed into continuous data by taking the value or the mean of the value of the response categories (Letourneau 2018)\n",
    "    \n",
    "    \n",
    "- Question 1: How often do you have a drink containing alcohol? \n",
    "    - Response categories: never, monthly or less, 2 to 4 times/month, 2 to 3 times/week, 4 or more times/week). \n",
    "- Question 2 How many drinks do you have on a typical day when you are drinking?\n",
    "    - Response categories: “1 or 2”, “3 or 4”, “5 or 6”, “7 to 9”, or “10 or more”\n",
    "- Question 3 How often do you have 5 or more drinks on one occasion?\n",
    "    - Response categories: “never”, “less than monthly”, “monthly”, “2-3 times”, or “4 or more times”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform clustering on individual auditc questions (3 total questions) from visit sequence 1\n",
    "data_first = data[data['VisitSeq'] == 1]\n",
    "data_allgroups_auditqs = data_first[['VisitSeq', 'Group', 'TBIID', 'auditc', 'AUDIT1', 'AUDIT2', 'AUDIT3']].set_index(['VisitSeq', 'Group', 'TBIID'])\n",
    "print(data_allgroups_auditqs.shape)\n",
    "data_allgroups_auditqs.dropna(axis=0, inplace=True)\n",
    "print(data_allgroups_auditqs.shape)\n",
    "data_allgroups_auditqs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tranformed\n",
    "data_allgroups_auditqs['AUDIT1_transf'] = data_allgroups_auditqs['AUDIT1'].replace({0:0, 1:0.5, 2:3, 3:10, 4:16})\n",
    "data_allgroups_auditqs['AUDIT2_transf'] = data_allgroups_auditqs['AUDIT2'].replace({0:1.5, 1:3.5, 2:5.5, 3:8, 4:10})\n",
    "data_allgroups_auditqs['AUDIT3_transf'] = data_allgroups_auditqs['AUDIT3'].replace({0:0, 1:0.5, 2:1, 3:2.5, 4:4})\n",
    "\n",
    "data_allgroups_auditqs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoding\n",
    "dummy_AUDIT1 = pd.get_dummies(data_allgroups_auditqs['AUDIT1'], prefix='AUDIT1', prefix_sep='_')\n",
    "dummy_AUDIT2 = pd.get_dummies(data_allgroups_auditqs['AUDIT2'], prefix='AUDIT2', prefix_sep='_')\n",
    "dummy_AUDIT3 = pd.get_dummies(data_allgroups_auditqs['AUDIT3'], prefix='AUDIT3', prefix_sep='_')\n",
    "\n",
    "data_allgroups_auditqs = pd.concat([data_allgroups_auditqs, dummy_AUDIT1, dummy_AUDIT2, dummy_AUDIT3], axis=1)\n",
    "data_allgroups_auditqs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make three data sets\n",
    "AUDIT_raw = data_allgroups_auditqs[['AUDIT1', 'AUDIT2', 'AUDIT3']]\n",
    "AUDIT_transf = data_allgroups_auditqs[['AUDIT1_transf', 'AUDIT2_transf','AUDIT3_transf']]\n",
    "AUDIT_onehot = data_allgroups_auditqs[['AUDIT1_0.0', 'AUDIT1_1.0', 'AUDIT1_2.0', 'AUDIT1_3.0', 'AUDIT1_4.0', \n",
    "                                      'AUDIT2_0.0', 'AUDIT2_1.0', 'AUDIT2_2.0', 'AUDIT2_3.0', 'AUDIT2_4.0', \n",
    "                                      'AUDIT3_0.0', 'AUDIT3_1.0', 'AUDIT3_2.0', 'AUDIT3_3.0', 'AUDIT3_4.0']]\n",
    "\n",
    "#create dic to save cluster evaluation metrics\n",
    "cluster_dic = {}\n",
    "\n",
    "# center and scale the data\n",
    "scaler = StandardScaler()\n",
    "#scaler = MinMaxScaler()\n",
    "#scaler = RobustScaler()\n",
    "\n",
    "AUDIT_raw_scaled = scaler.fit_transform(AUDIT_raw)\n",
    "AUDIT_transf_scaled = scaler.fit_transform(AUDIT_transf)\n",
    "AUDIT_onehot_scaled = scaler.fit_transform(AUDIT_onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare kmeans, GMM, kmodes, and kmedians"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = AUDIT_raw_scaled\n",
    "\n",
    "#pick cluster number based on silhouette coefficient\n",
    "k_range = range(2,7)\n",
    "\n",
    "base_scores = []\n",
    "sil_scores = []\n",
    "db_scores = []\n",
    "ch_scores = []\n",
    "mse_scores = []\n",
    "\n",
    "for k in k_range:\n",
    "    km_ss = KMeans(n_clusters=k, random_state=39)\n",
    "    km_ss.fit(data)\n",
    "    \n",
    "    base_scores.append(-km_ss.score(data))\n",
    "    sil_scores.append(metrics.silhouette_score(data, km_ss.labels_))\n",
    "    db_scores.append(metrics.davies_bouldin_score(data, km_ss.labels_))\n",
    "    ch_scores.append(metrics.calinski_harabasz_score(data, km_ss.labels_))\n",
    "    mse_scores.append(km_ss.inertia_)\n",
    "    \n",
    "# plot the results\n",
    "plt.plot(k_range, base_scores)\n",
    "plt.title('AUDIT-C Questions K means clustering')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Base score')\n",
    "plt.show()\n",
    "\n",
    "# plot the results\n",
    "plt.plot(k_range, sil_scores)\n",
    "plt.title('AUDIT-C Questions K means clustering')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Silhouette Coefficient')\n",
    "plt.show()\n",
    "\n",
    "# plot the results\n",
    "plt.plot(k_range, db_scores)\n",
    "plt.title('AUDIT-C Questions K means clustering')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Davies Bouldin Score')\n",
    "plt.show()\n",
    "\n",
    "# plot the results\n",
    "plt.plot(k_range, ch_scores)\n",
    "plt.title('AUDIT-C Questions K means clustering')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Calinski Harabasz Score')\n",
    "plt.show()\n",
    "    \n",
    "# plot the results\n",
    "plt.plot(k_range, mse_scores)\n",
    "plt.title('AUDIT-C Questions K means clustering')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Inertia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expectation-maximization (Gaussian Mixture Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "k_range = range(2,10)\n",
    "\n",
    "gm_score=[]\n",
    "gm_aic=[]\n",
    "gm_bic= []\n",
    "\n",
    "for k in k_range:\n",
    "    gm = GaussianMixture(n_components=k, random_state=39)\n",
    "    gm.fit(data)\n",
    "    \n",
    "    gm_score.append(gm.score(data))\n",
    "    gm_aic.append(gm.aic(data))\n",
    "    gm_bic.append(gm.bic(data))\n",
    "\n",
    "# plot the results\n",
    "plt.plot(k_range, gm_score)\n",
    "plt.title('AUDIT-C Questions GMM')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Base score')\n",
    "plt.show()\n",
    "\n",
    "# plot the results\n",
    "plt.plot(k_range, gm_aic)\n",
    "plt.title('AUDIT-C Questions GMM')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('AIC')\n",
    "plt.show()\n",
    "\n",
    "# plot the results\n",
    "plt.plot(k_range, gm_bic)\n",
    "plt.title('AUDIT-C Questions GMM')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('BIC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kmediods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pick cluster number based on silhouette coefficient\n",
    "k_range = range(2,10)\n",
    "scores = []\n",
    "for k in k_range:\n",
    "    kmed_ss = KMedoids(n_clusters=k, random_state=39)\n",
    "    kmed_ss.fit_predict(data)\n",
    "    scores.append(kmed_ss.inertia_)\n",
    "\n",
    "# plot the results\n",
    "plt.plot(k_range, scores)\n",
    "plt.title('AUDIT-C Questions K mediods clustering')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Inertia')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kmodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pick cluster number based on silhouette coefficient\n",
    "k_range = range(2,10)\n",
    "scores = []\n",
    "for k in k_range:\n",
    "    kmode_ss = KModes(n_clusters=k, random_state=39)\n",
    "    kmode_ss.fit(data)\n",
    "    scores.append(metrics.silhouette_score(data, kmode_ss.labels_))\n",
    "\n",
    "# plot the results\n",
    "plt.plot(k_range, scores)\n",
    "plt.title('AUDIT-C Questions K Modes clustering')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Silhouette Coefficient')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Focus on AUDIT_raw_scaled; find best fit cluster number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dendrogram to determine cluster number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#viz dendrogram to find if three clusters makes sense\n",
    "plt.figure(figsize=(10, 7))  \n",
    "plt.title(\"AUDIT-C 3 Question Dendrogram\")  \n",
    "plt.ylabel(\"Distance (dissimilarity)\")\n",
    "plt.xlabel(\"Participants\")\n",
    "dend = shc.dendrogram(shc.linkage(AUDIT_raw_scaled, method='ward'), \n",
    "                      distance_sort='ascending',\n",
    "                      show_leaf_counts=True, leaf_font_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#viz clustering with heat map of AUDIT-C answers\n",
    "sns.clustermap(AUDIT_raw_scaled, metric=\"euclidean\", standard_scale=1, method=\"ward\", cmap=\"Blues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### kmeans determine stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine stability metrics with different k clusters\n",
    "km_3 = KMeans(n_clusters=2,random_state=99)\n",
    "km_3.fit(AUDIT_raw_scaled)\n",
    "orig_clusters = km_3.labels_\n",
    "\n",
    "scores = {}\n",
    "homogeneity_score_list = []\n",
    "completeness_score_list = []\n",
    "v_measure_score_list = []\n",
    "adjusted_rand_score_list = []\n",
    "adjusted_mutual_info_score_list = []\n",
    "\n",
    "for i in range(1,99,3):\n",
    "\n",
    "    #choose k=3 clusters and fit data\n",
    "    km_3_int = KMeans(n_clusters=4,random_state=i)\n",
    "    km_3_int.fit(AUDIT_raw_scaled)\n",
    "    int_clusters = km_3_int.labels_\n",
    "    \n",
    "    #compute metrics\n",
    "    homogeneity_score_int = metrics.homogeneity_score(orig_clusters, int_clusters)\n",
    "    completeness_score_int = metrics.completeness_score(orig_clusters, int_clusters)\n",
    "    v_measure_score_int = metrics.v_measure_score(orig_clusters, int_clusters)\n",
    "    adjusted_rand_score_int = metrics.adjusted_rand_score(orig_clusters, int_clusters)\n",
    "    adjusted_mutual_info_score_int = metrics.adjusted_mutual_info_score(orig_clusters,  int_clusters)\n",
    "    \n",
    "    homogeneity_score_list.append(homogeneity_score_int)\n",
    "    completeness_score_list.append(completeness_score_int)\n",
    "    v_measure_score_list.append(v_measure_score_int)\n",
    "    adjusted_rand_score_list.append(adjusted_rand_score_int)\n",
    "    adjusted_mutual_info_score_list.append(adjusted_mutual_info_score_int)\n",
    "    \n",
    "scores['homogeneity_score'] = homogeneity_score_list\n",
    "scores['completeness_score'] = completeness_score_list\n",
    "scores['v_measure_score'] = v_measure_score_list\n",
    "scores['adjusted_rand_score'] = adjusted_rand_score_list\n",
    "scores['adjusted_mutual_info_score'] = adjusted_mutual_info_score_list\n",
    "\n",
    "scores_k2 = pd.DataFrame.from_dict(scores).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data=[scores_k2, scores_k3, scores_k4], index=['k=2', 'k=3', 'k=4'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kmeans clustering on AUDIT_raw_scaled with k=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose k=3 clusters and fit data\n",
    "km_3 = KMeans(n_clusters=3,random_state=99)\n",
    "km_3.fit(AUDIT_raw_scaled)\n",
    "#new df for cluster info\n",
    "data_allgroups_auditqs_clusters = data_allgroups_auditqs\n",
    "data_allgroups_auditqs_clusters = data_allgroups_auditqs_clusters.reset_index()\n",
    "data_allgroups_auditqs_clusters['kmeans_cluster'] = [\"cluster_\" + str(label) for label in km_3.labels_ ]\n",
    "print(data_allgroups_auditqs_clusters.shape)\n",
    "data_allgroups_auditqs_clusters.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_allgroups_auditqs_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge with orig df so each TBIID entry has its corr cluster assignment added\n",
    "data_clusters = pd.merge(data_first, data_allgroups_auditqs_clusters[['TBIID', 'kmeans_cluster']], on=['TBIID'], how='outer')\n",
    "print(data_clusters.shape)\n",
    "print(data_clusters['kmeans_cluster'].value_counts())\n",
    "data_clusters.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#viz cluster grouping and auditc answers - seems to be low(1), high freq(2), and binge clusters(0)\n",
    "auditc_cols = ['auditc', 'AUDIT1', 'AUDIT2', 'AUDIT3']\n",
    "for variable in auditc_cols:\n",
    "    try:\n",
    "        plt.figure(figsize=(7,7))\n",
    "        g = sns.barplot(x='kmeans_cluster', y=variable, data=data_clusters[data_clusters['VisitSeq'] == 1], ci=68, palette=\"rocket\", order=[\"cluster_0\", \"cluster_1\", \"cluster_2\"])\n",
    "        plt.show()\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename clusters for easier viz understanding\n",
    "data_clusters.replace({'kmeans_cluster': {'cluster_0':'freq', 'cluster_1':'binge','cluster_2':'low',}}, inplace=True)\n",
    "#look at counts in each cluster for each group (is there a difference in cluster patterns between groups?)\n",
    "data_clusters[data_clusters['VisitSeq'] == 1].groupby(['Group'])['kmeans_cluster'].value_counts().reset_index(name='count').sort_values(['Group', 'kmeans_cluster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, perplexity=50, random_state=1234)\n",
    "tsne_features = tsne.fit_transform(AUDIT_transf_scaled)\n",
    "\n",
    "print(tsne_features.shape)\n",
    "tsne_df = pd.DataFrame(data = tsne_features, columns = ['tsne_0', 'tsne_1'], index = data_allgroups_auditqs_clusters.index)\n",
    "data_allgroups_auditqs_clusters_TSNE = pd.concat([data_allgroups_auditqs_clusters, tsne_df], axis = 1)\n",
    "data_allgroups_auditqs_clusters_TSNE.replace({'kmeans_cluster': {'cluster_0':'freq', 'cluster_1':'binge','cluster_2':'low',}}, inplace=True)\n",
    "data_allgroups_auditqs_clusters_TSNE.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "sns.scatterplot(x='tsne_0', y='tsne_1', data=data_allgroups_auditqs_clusters_TSNE, hue='kmeans_cluster')\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, .95))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try SOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clusters_v1 = data_clusters[data_clusters['VisitSeq'] == 1]\n",
    "data_clusters_v1['kmeans_cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participants = data_allgroups_auditqs.reset_index(['TBIID'])['TBIID'].values\n",
    "categories = data_clusters_v1['kmeans_cluster']\n",
    "\n",
    "category_color = {'C': 'darkgreen',\n",
    "                  'T': 'darkorange'}\n",
    "\n",
    "category_color = {'low': 'darkgreen',\n",
    "                  'freq': 'limegreen',\n",
    "                  'heavy': 'darkorange',\n",
    "                  'binge': 'crimson'}\n",
    "\n",
    "colors_dict = {c: category_color[dm] for c, dm in zip(participants, categories)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = AUDIT_transf_scaled\n",
    "size = 15\n",
    "som = MiniSom(size, size, len(X[0]),\n",
    "              neighborhood_function='gaussian', sigma=1.5,\n",
    "              random_seed=39)\n",
    "\n",
    "som.pca_weights_init(X)\n",
    "som.train_random(X, 5000, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "som_map = som.labels_map(X, participants)\n",
    "  \n",
    "plt.figure(figsize=(10, 5))\n",
    "for p, countries in som_map.items():\n",
    "    countries = list(countries)\n",
    "    x = p[0] + .1\n",
    "    y = p[1] - .3\n",
    "    for i, c in enumerate(countries):\n",
    "        off_set = (i+1)/len(countries) - 0.05\n",
    "        plt.text(x, y+off_set, c, color=colors_dict[c], fontsize=10)\n",
    "plt.pcolor(som.distance_map().T, cmap='gray_r', alpha=.2)\n",
    "plt.xticks(np.arange(size+1))\n",
    "plt.yticks(np.arange(size+1))\n",
    "plt.grid()\n",
    "\n",
    "legend_elements = [Patch(facecolor=clr,\n",
    "                         edgecolor='w',\n",
    "                         label=l) for l, clr in category_color.items()]\n",
    "plt.legend(handles=legend_elements, loc='center left', bbox_to_anchor=(1, .95))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = som.get_weights()\n",
    "plt.figure(figsize=(10, 10))\n",
    "feature_names = ['AUDIT1_transf', 'AUDIT2_transf','AUDIT3_transf']\n",
    "for i, f in enumerate(feature_names):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    plt.title(f)\n",
    "    plt.pcolor(W[:,:,i].T, cmap='coolwarm')\n",
    "    plt.xticks(np.arange(size+1))\n",
    "    plt.yticks(np.arange(size+1))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.zeros((size, size))\n",
    "plt.figure(figsize=(8, 8))\n",
    "for i in np.arange(som._weights.shape[0]):\n",
    "    for j in np.arange(som._weights.shape[1]):\n",
    "        feature = np.argmax(W[i, j , :])\n",
    "        plt.plot([j+.5], [i+.5], 'o', color='C'+str(feature),\n",
    "                 marker='s', markersize=24)\n",
    "\n",
    "legend_elements = [Patch(facecolor='C'+str(i),\n",
    "                         edgecolor='w',\n",
    "                         label=f) for i, f in enumerate(feature_names)]\n",
    "\n",
    "plt.legend(handles=legend_elements,\n",
    "           loc='center left',\n",
    "           bbox_to_anchor=(1, .95))\n",
    "        \n",
    "plt.xlim([0, size])\n",
    "plt.ylim([0, size])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TBI only add'n analysis and viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select just TBI participants and exclude visit '88' for add'l analysis\n",
    "visit_seq = [1,2]\n",
    "data_clusters_TBI = data_clusters[(data_clusters['Group'] == 'T') & (data_clusters['VisitSeq'].isin(visit_seq))]\n",
    "data_clusters_TBI.to_csv('data_clusters_TBI.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#viz for first visit seq\n",
    "\n",
    "data_viz = data_clusters_TBI[data_clusters_TBI['VisitSeq'] == 1]\n",
    "\n",
    "cont_vars = ['servconn', 'cestotal', 'MnthSncBlst', 'QKOIorA', 'QKOExpMil', 'QKOAllMil', 'QKOLife',\n",
    "       'QBlstExp', 'QBEACRM', 'Q5plus2', 'QEDist_sum', 'QEDist_mean',\n",
    "       'QEDist_min', 'auditc', 'AUDIT1', 'AUDIT2', 'AUDIT3', 'DOPA', 'DA',\n",
    "       'DOPAC', 'NE', 'DHPG', 'da_dopa_ratio', 'dopac_da_ratio',\n",
    "       'ne_dopa_ratio', 'dhpg_ne_ratio', \n",
    "       'BMI', 'BPSYS', 'BPDIAS', 'HRATE', 'BGlucose', 'BNa', 'BUN', 'BCreat', 'BOsmo',\n",
    "       'UOsmo', 'USG', 'UNa', 'BK', 'TotalChol', 'LDL', 'HDL', 'Trig', 'CSFPROTEIN_x',\n",
    "       'CSFGLUCOSE', 'CSFRBCS',  \n",
    "       'CAPSTotal', 'PSQIc1', 'PSQIc2', 'PSQIc3', 'PSQIc4', 'PSQIc5',\n",
    "       'PSQIc6', 'PSQIc7', 'PSQItot', 'PCLTot', 'PCL_reexp', 'PCL_avoid',\n",
    "       'PCL_numb', 'PCL_hyper', 'PHQTot', 'PHQ_psych', 'PHQ_somatic',\n",
    "       'NSITot', 'TBITot', 'NSI_vestibular', 'NSI_somatosensory',\n",
    "       'NSI_cognitive', 'NSI_affective', 'NSI_ERP_affective',\n",
    "       'NIS_ERP_vestsom', \n",
    "            'Amygdala_l', 'Amygdala_r',\n",
    "       'Pallidum_l', 'Pallidum_r', 'Midbrain', 'auditc',\n",
    "            'Plasma1_bFGF',\n",
    "       'Plasma1_CRP', 'Plasma1_Eotaxin', 'Plasma1_Eotaxin3',\n",
    "       'Plasma1_Flt1', 'Plasma1_ICAM1', 'Plasma1_IFNγ', 'Plasma1_IL10',\n",
    "       'Plasma1_IL12_IL23p40', 'Plasma1_IL12p70', 'Plasma1_IL15',\n",
    "       'Plasma1_IL16', 'Plasma1_IL17A', 'Plasma1_IL1α', 'Plasma1_IL6',\n",
    "       'Plasma1_IL7', 'Plasma1_IL8', 'Plasma1_IP10', 'Plasma1_MCP1',\n",
    "       'Plasma1_MCP4', 'Plasma1_MDC', 'Plasma1_MIP1α', 'Plasma1_MIP1β',\n",
    "       'Plasma1_PlGF', 'Plasma1_SAA', 'Plasma1_TARC', 'Plasma1_Tie2',\n",
    "       'Plasma1_TNFα', 'Plasma1_TNFβ', 'Plasma1_VCAM1', 'Plasma1_VEGF',\n",
    "       'Plasma1_VEGFC', 'Plasma1_VEGFD']\n",
    "    \n",
    "for param in cont_vars:\n",
    "    print(param)\n",
    "    \n",
    "    try:\n",
    "        g = sns.catplot(x='kmeans_cluster', y=param, kind='bar', data=data_viz, ci=68, height=5, aspect=4)\n",
    "        plt.show()\n",
    "        \n",
    "        print('\\n')\n",
    "        \n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#viz for first visit seq\n",
    "\n",
    "data_cat = ['Status_x', 'VisitSeq', 'GType', 'Race', 'Hispanic', 'Handedness', 'Marital', 'APOEGen', \n",
    "           'HYPERTEN', 'HYPERCHO', 'DIABETES', 'B12DEF', 'THYROID',\n",
    "           'MHxPain', 'MHxHA', 'MHxHtn', 'MHxCard', 'MHxGI', 'MHxNeuro', 'MHxLung', 'MHxApnea', \n",
    "            'SCPTSD', 'SCMDD', 'SCPD', 'SCGAD', 'SCNone', 'capsCrtA']\n",
    "\n",
    "data_audit = ['auditc', 'AUDIT1', 'AUDIT2', 'AUDIT3']\n",
    "\n",
    "data_viz = data_clusters_TBI[data_clusters_TBI['VisitSeq'] == 1]\n",
    "\n",
    "for param in data_cat:\n",
    "    print(param)\n",
    "\n",
    "    data_int = (data_viz[data_viz[param] != 9].groupby('kmeans_cluster')[param].value_counts() /\n",
    "                data_viz[data_viz[param] != 9].groupby('kmeans_cluster')[param].count()).reset_index(name='perc')\n",
    "        \n",
    "    try:\n",
    "        g = sns.catplot(x=param, y='perc', kind='bar', data=data_int, hue='kmeans_cluster', ci=68, height=5, aspect=4)\n",
    "        plt.show()\n",
    "        \n",
    "        print('\\n')\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "for param in data_audit:\n",
    "    print(param)\n",
    "\n",
    "    data_int = (data_viz.groupby('kmeans_cluster')[param].value_counts() /\n",
    "                        data_viz.groupby('kmeans_cluster')[param].count()).reset_index(name='perc')\n",
    "        \n",
    "    try:\n",
    "        g = sns.catplot(x=param, y='perc', kind='bar', data=data_int, hue='kmeans_cluster', ci=68, height=5, aspect=4)\n",
    "        plt.show()\n",
    "        \n",
    "        print('\\n')\n",
    "        \n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#does drinking cluster affect follow-up visits\n",
    "print(data_clusters_TBI.groupby(['VisitSeq', 'kmeans_cluster'])['kmeans_cluster'].count())\n",
    "sns.countplot(x='VisitSeq', data=data_clusters_TBI, hue='kmeans_cluster', palette=\"rocket\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get TBIIDs of participants with a second visit and use to filter\n",
    "TBIID_v2 = data_clusters_TBI[data_clusters_TBI['VisitSeq'] == 2]['TBIID'].values\n",
    "\n",
    "#create new df with only participants who came to both visits 1 and 2\n",
    "data_clusters_TBI_v12_only = data_clusters_TBI[data_clusters_TBI['TBIID'].isin(TBIID_v2)]\n",
    "print(data_clusters_TBI_v12_only.shape)\n",
    "data_clusters_TBI_v12_only.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#viz for first visit seq\n",
    "\n",
    "data_viz = data_clusters_TBI_v12_only\n",
    "\n",
    "for param in cont_vars:\n",
    "    print(param)\n",
    "    \n",
    "    try:\n",
    "        g = sns.catplot(x='VisitSeq', y=param, kind='bar', hue='kmeans_cluster', data=data_viz, ci=68, height=5, aspect=4)\n",
    "        plt.show()\n",
    "        \n",
    "        print('\\n')\n",
    "        \n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select only visit 1\n",
    "data_clusters = data_clusters[data_clusters['VisitSeq'] == 1]\n",
    "data_clusters.to_csv('data_clusters.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get AUDIT counts and percents for chi squared analysis and viz\n",
    "AUDIT_tot_counts = data_allgroups_auditqs_clusters.groupby('Group')['auditc'].value_counts().reset_index(name='count').sort_values(['Group', 'auditc'])\n",
    "AUDIT_1_counts = data_allgroups_auditqs_clusters.groupby('Group')['AUDIT1'].value_counts().reset_index(name='count').sort_values(['Group', 'AUDIT1'])\n",
    "AUDIT_2_counts = data_allgroups_auditqs_clusters.groupby('Group')['AUDIT2'].value_counts().reset_index(name='count').sort_values(['Group', 'AUDIT2'])\n",
    "AUDIT_3_counts = data_allgroups_auditqs_clusters.groupby('Group')['AUDIT3'].value_counts().reset_index(name='count').sort_values(['Group', 'AUDIT3'])\n",
    "AUDIT_tot_counts.to_csv('AUDIT_tot_counts.csv')\n",
    "AUDIT_1_counts.to_csv('AUDIT_1_counts.csv')\n",
    "AUDIT_2_counts.to_csv('AUDIT_2_counts.csv')\n",
    "AUDIT_3_counts.to_csv('AUDIT_3_counts.csv')\n",
    "\n",
    "AUDIT_tot_perc = (data_allgroups_auditqs_clusters.groupby('Group')['auditc'].value_counts() / data_allgroups_auditqs_clusters.groupby('Group')['auditc'].count()).reset_index(name='perc').sort_values(['Group', 'auditc'])\n",
    "AUDIT_1_perc = (data_allgroups_auditqs_clusters.groupby('Group')['AUDIT1'].value_counts() / data_allgroups_auditqs_clusters.groupby('Group')['AUDIT1'].count()).reset_index(name='perc').sort_values(['Group', 'AUDIT1'])\n",
    "AUDIT_2_perc = (data_allgroups_auditqs_clusters.groupby('Group')['AUDIT2'].value_counts() / data_allgroups_auditqs_clusters.groupby('Group')['AUDIT2'].count()).reset_index(name='perc').sort_values(['Group', 'AUDIT2'])\n",
    "AUDIT_3_perc = (data_allgroups_auditqs_clusters.groupby('Group')['AUDIT3'].value_counts() / data_allgroups_auditqs_clusters.groupby('Group')['AUDIT3'].count()).reset_index(name='perc').sort_values(['Group', 'AUDIT3'])\n",
    "AUDIT_tot_perc.to_csv('AUDIT_tot_perc.csv')\n",
    "AUDIT_1_perc.to_csv('AUDIT_1_perc.csv')\n",
    "AUDIT_2_perc.to_csv('AUDIT_2_perc.csv')\n",
    "AUDIT_3_perc.to_csv('AUDIT_3_perc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get value counts for AUDIT-C for each cluster (not split by group)\n",
    "AUDIT_tot_counts_cluster = data_clusters.groupby(['kmeans_cluster'])['auditc'].value_counts().reset_index(name='count').sort_values(['kmeans_cluster', 'auditc'])\n",
    "AUDIT_1_counts_cluster = data_clusters.groupby(['kmeans_cluster'])['AUDIT1'].value_counts().reset_index(name='count').sort_values(['kmeans_cluster', 'AUDIT1'])\n",
    "AUDIT_2_counts_cluster = data_clusters.groupby(['kmeans_cluster'])['AUDIT2'].value_counts().reset_index(name='count').sort_values(['kmeans_cluster', 'AUDIT2'])\n",
    "AUDIT_3_counts_cluster = data_clusters.groupby(['kmeans_cluster'])['AUDIT3'].value_counts().reset_index(name='count').sort_values(['kmeans_cluster', 'AUDIT3'])\n",
    "AUDIT_tot_counts_cluster.to_csv('AUDIT_tot_counts_cluster.csv')\n",
    "AUDIT_1_counts_cluster.to_csv('AUDIT_1_counts_cluster.csv')\n",
    "AUDIT_2_counts_cluster.to_csv('AUDIT_2_counts_cluster.csv')\n",
    "AUDIT_3_counts_cluster.to_csv('AUDIT_3_counts_cluster.csv')\n",
    "\n",
    "AUDIT_tot_perc_cluster = (data_clusters.groupby(['kmeans_cluster'])['auditc'].value_counts() / data_clusters.groupby(['kmeans_cluster'])['auditc'].count()).reset_index(name='perc').sort_values(['kmeans_cluster', 'auditc'])\n",
    "AUDIT_1_perc_cluster = (data_clusters.groupby(['kmeans_cluster'])['AUDIT1'].value_counts() / data_clusters.groupby(['kmeans_cluster'])['AUDIT1'].count()).reset_index(name='perc').sort_values(['kmeans_cluster', 'AUDIT1'])\n",
    "AUDIT_2_perc_cluster = (data_clusters.groupby(['kmeans_cluster'])['AUDIT2'].value_counts() / data_clusters.groupby(['kmeans_cluster'])['AUDIT2'].count()).reset_index(name='perc').sort_values(['kmeans_cluster', 'AUDIT2'])\n",
    "AUDIT_3_perc_cluster = (data_clusters.groupby(['kmeans_cluster'])['AUDIT3'].value_counts()/ data_clusters.groupby(['kmeans_cluster'])['AUDIT3'].count()).reset_index(name='perc').sort_values(['kmeans_cluster', 'AUDIT3'])\n",
    "AUDIT_tot_perc_cluster.to_csv('AUDIT_tot_perc_cluster.csv')\n",
    "AUDIT_1_perc_cluster.to_csv('AUDIT_1_perc_cluster.csv')\n",
    "AUDIT_2_perc_cluster.to_csv('AUDIT_2_perc_cluster.csv')\n",
    "AUDIT_3_perc_cluster.to_csv('AUDIT_3_perc_cluster.csv')\n",
    "\n",
    "#get value counts by group for each cluster\n",
    "AUDIT_cluster_counts = data_clusters.groupby('Group')['kmeans_cluster'].value_counts().reset_index(name='count').sort_values(['Group', 'kmeans_cluster'])\n",
    "AUDIT_cluster_perc = (data_clusters.groupby('Group')['kmeans_cluster'].value_counts() / data_clusters.groupby('Group')['kmeans_cluster'].count()).reset_index(name='perc').sort_values(['Group', 'kmeans_cluster'])\n",
    "AUDIT_cluster_counts.to_csv('AUDIT_cluster_counts.csv')\n",
    "AUDIT_cluster_perc.to_csv('AUDIT_cluster_perc.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
