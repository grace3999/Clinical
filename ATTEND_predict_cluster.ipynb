{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "#visualizing results\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_context('poster')\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "import scipy.cluster.hierarchy as shc\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GroupKFold, train_test_split, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC, LinearSVC \n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import auc, accuracy_score, confusion_matrix, mean_squared_error, roc_auc_score\n",
    "\n",
    "import shap\n",
    "# load JS visualization code to notebook\n",
    "shap.initjs()\n",
    "\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data_bl = '/Users/abbieschindler/Documents/ProgrammingFun/iPythonScripts/Clinial/data_bl.csv'\n",
    "path_data_fu = '/Users/abbieschindler/Documents/ProgrammingFun/iPythonScripts/Clinial/data_fu.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bl = pd.read_csv(path_data_bl, encoding='latin1', index_col=0)\n",
    "data_bl = pd.DataFrame(data=data_bl)\n",
    "print(data_bl.shape)\n",
    "print(data_bl['VisitID'].value_counts())\n",
    "data_bl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fu = pd.read_csv(path_data_fu, encoding='latin1', index_col=0)\n",
    "data_fu = pd.DataFrame(data=data_fu)\n",
    "print(data_fu.shape)\n",
    "print(data_fu['VisitID'].value_counts())\n",
    "data_fu.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create cluster df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_PCL = data_bl[['level_0', 'pcl5total']]\n",
    "data_PCL['level_0fu'] = data_fu['level_0']\n",
    "data_PCL['pcl5total_fu'] = data_fu['pcl5total']\n",
    "data_PCL['pcl_diff'] = (data_PCL['pcl5total_fu'] - data_PCL['pcl5total'])\n",
    "print(data_PCL.shape)\n",
    "data_PCL = data_PCL.dropna()\n",
    "print(data_PCL.shape)\n",
    "data_PCL.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### determine cluster number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_PCLfeat = data_PCL[['pcl5total', \n",
    "                         'pcl5total_fu', 'pcl_diff']]\n",
    "# center and scale the data\n",
    "scaler = StandardScaler()\n",
    "#scaler = RobustScaler()\n",
    "\n",
    "data_PCLfeat_scaled = scaler.fit_transform(data_PCLfeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = data_PCLfeat_scaled\n",
    "\n",
    "#pick cluster number based on silhouette coefficient\n",
    "k_range = range(2,15)\n",
    "\n",
    "base_scores = []\n",
    "sil_scores = []\n",
    "db_scores = []\n",
    "ch_scores = []\n",
    "mse_scores = []\n",
    "\n",
    "for k in k_range:\n",
    "    km_ss = KMeans(n_clusters=k, random_state=39)\n",
    "    km_ss.fit(data)\n",
    "    \n",
    "    sil_scores.append(silhouette_score(data, km_ss.labels_))\n",
    "    db_scores.append(davies_bouldin_score(data, km_ss.labels_))\n",
    "    #ch_scores.append(calinski_harabasz_score(data, km_ss.labels_))\n",
    "    mse_scores.append(km_ss.inertia_)\n",
    "    \n",
    "# plot the results\n",
    "plt.plot(k_range, sil_scores)\n",
    "plt.title('AUDIT-C Questions K means clustering')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Silhouette Coefficient')\n",
    "plt.show()\n",
    "\n",
    "# plot the results\n",
    "plt.plot(k_range, db_scores)\n",
    "plt.title('AUDIT-C Questions K means clustering')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Davies Bouldin Score')\n",
    "plt.show()\n",
    "    \n",
    "# plot the results\n",
    "plt.plot(k_range, mse_scores)\n",
    "plt.title('AUDIT-C Questions K means clustering')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Inertia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#viz dendrogram to find if three clusters makes sense\n",
    "plt.figure(figsize=(10, 7))  \n",
    "plt.title(\"Dendrogram\")  \n",
    "plt.ylabel(\"Distance (dissimilarity)\")\n",
    "plt.xlabel(\"Participants\")\n",
    "dend = shc.dendrogram(shc.linkage(data_PCLfeat_scaled, method='ward'), \n",
    "                      distance_sort='ascending',\n",
    "                      show_leaf_counts=True, leaf_font_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#viz clustering with heat map of AUDIT-C answers\n",
    "sns.clustermap(data_PCLfeat_scaled, metric=\"euclidean\", standard_scale=1, method=\"ward\", cmap=\"Blues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose k=3 clusters and fit data\n",
    "km_3 = KMeans(n_clusters=3,random_state=39)\n",
    "km_3.fit(data_PCLfeat_scaled)\n",
    "#add cluster info to df\n",
    "data_PCL['kmeans_cluster'] = [\"cluster_\" + str(label) for label in km_3.labels_ ]\n",
    "print(data_PCL.shape)\n",
    "print(data_PCL['kmeans_cluster'].value_counts())\n",
    "data_PCL.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_PCL['kmeans_cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols = ['pcl5total', 'pcl5total_fu', 'pcl_diff']\n",
    "\n",
    "for variable in cols:\n",
    "    try:\n",
    "        plt.figure(figsize=(7,7))\n",
    "        g = sns.barplot(x='kmeans_cluster', y=variable, data=data_PCL, ci=68, palette=\"rocket\", order=[\"cluster_0\", \"cluster_1\", \"cluster_2\"])\n",
    "        plt.show()\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_PCL.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melt = pd.melt(data_PCL, id_vars=['level_0', 'kmeans_cluster'], value_vars=['pcl5total', 'pcl5total_fu'],\n",
    "              var_name='timepoint', value_name='PCL5total')\n",
    "melt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(x=\"timepoint\", y=\"PCL5total\", hue=\"kmeans_cluster\",\n",
    "                capsize=.2, height=7, aspect=1,\n",
    "                kind=\"point\", data=melt, palette=['green', 'darkorange', 'red'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try to predict cluster assignment based on exposure at bl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add cluster info back to original df\n",
    "cluster_dict = dict(zip(data_PCL['level_0'], data_PCL['kmeans_cluster']))\n",
    "data_bl['cluster'] = data_bl['level_0'].map(cluster_dict)\n",
    "\n",
    "#create int cluster column\n",
    "data_PCL['kmeans_cluster_num'] = [int(x.split('_')[-1]) for x in data_PCL['kmeans_cluster']]\n",
    "cluster_dict = dict(zip(data_PCL['level_0'], data_PCL['kmeans_cluster_num']))\n",
    "data_bl['cluster_num'] = data_bl['level_0'].map(cluster_dict)\n",
    "print(data_bl.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep = ['level_0', 'VisitID', 'age', 'gender',\n",
    "       'attendDem_HCW', 'lecAtotal', \n",
    "         'ceaAPi1', 'ceaAPi2',\n",
    "       'ceaAPi3', 'ceaMC', 'ceaPriorTimeWeeks', 'ceaPTWi1', 'ceaPTWi2',\n",
    "       'ceaPTWi3', 'ceaPTWi4', 'ceaPTWi5', 'ceaPTWi6', 'ceaPTWi7',\n",
    "       'ceaPTWi8', 'ceaPTWi9', 'ceaPTWi10', 'ceaPTWi11', 'ceaPTWi12',\n",
    "       'ceaPTWi13', 'phq9i1', 'phq9i2', 'phq9i3', 'phq9i4', 'phq9i5',\n",
    "       'phq9i6', 'phq9i7', 'phq9i8', 'phq9i9', 'stni1', 'stni10a',\n",
    "       'stni11a', 'stni2', 'stni3', 'stni4', 'stni5', 'stni6', 'stni7',\n",
    "       'stni8', 'stni9', 'gad7i1', 'gad7i2', 'gad7i3', 'gad7i4', 'gad7i5',\n",
    "       'gad7i6', 'gad7i7', 'isi1', 'isi2', 'isi3', 'isi4', 'isi5', 'isi6',\n",
    "       'isi7', 'infield', 'work', 'cluster', 'cluster_num']\n",
    "\n",
    "data_bl_dropna = data_bl[keep].dropna()\n",
    "print(data_bl_dropna.shape)\n",
    "data_bl_dropna.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create/map factors\n",
    "gender_dict = {'F': 0, 'M': 1, 'NB': 2, 'O':3}\n",
    "data_bl_dropna['gender'] = data_bl_dropna['gender'].map(gender_dict)\n",
    "data_bl_dropna['gender'] = data_bl_dropna['gender'].astype(object)\n",
    "\n",
    "HCW_dict = {True: 0, False: 1}\n",
    "data_bl_dropna['attendDem_HCW'] = data_bl_dropna['attendDem_HCW'].map(HCW_dict)\n",
    "data_bl_dropna['attendDem_HCW'] = data_bl_dropna['attendDem_HCW'].astype(object)\n",
    "\n",
    "data_bl_dropna['cluster_num'] = data_bl_dropna['cluster_num'].astype('int')\n",
    "#data_bl_dropna['cluster_num'] = data_bl_dropna['cluster_num'].astype(object)\n",
    "\n",
    "print(data_bl_dropna.shape)\n",
    "data_bl_dropna.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_exposure = ['age', 'gender', 'attendDem_HCW', 'lecAtotal', \n",
    "         'ceaAPi1', 'ceaAPi2',\n",
    "       'ceaAPi3', 'ceaMC', 'ceaPriorTimeWeeks', 'ceaPTWi1', 'ceaPTWi2',\n",
    "       'ceaPTWi3', 'ceaPTWi4', 'ceaPTWi5', 'ceaPTWi6', 'ceaPTWi7',\n",
    "       'ceaPTWi8', 'ceaPTWi9', 'ceaPTWi10', 'ceaPTWi11', 'ceaPTWi12',\n",
    "       'ceaPTWi13']\n",
    "\n",
    "features_MH = ['age', 'gender', 'attendDem_HCW',\n",
    "              'phq9i1', 'phq9i2', 'phq9i3', 'phq9i4', 'phq9i5',\n",
    "       'phq9i6', 'phq9i7', 'phq9i8', 'phq9i9', 'stni1', 'stni10a',\n",
    "       'stni11a', 'stni2', 'stni3', 'stni4', 'stni5', 'stni6', 'stni7',\n",
    "       'stni8', 'stni9', 'gad7i1', 'gad7i2', 'gad7i3', 'gad7i4', 'gad7i5',\n",
    "       'gad7i6', 'gad7i7', 'isi1', 'isi2', 'isi3', 'isi4', 'isi5', 'isi6',\n",
    "       'isi7']\n",
    "\n",
    "features_all = ['age', 'gender', 'attendDem_HCW', 'lecAtotal', \n",
    "         'ceaAPi1', 'ceaAPi2',\n",
    "       'ceaAPi3', 'ceaMC', 'ceaPriorTimeWeeks', 'ceaPTWi1', 'ceaPTWi2',\n",
    "       'ceaPTWi3', 'ceaPTWi4', 'ceaPTWi5', 'ceaPTWi6', 'ceaPTWi7',\n",
    "       'ceaPTWi8', 'ceaPTWi9', 'ceaPTWi10', 'ceaPTWi11', 'ceaPTWi12',\n",
    "       'ceaPTWi13', 'phq9i1', 'phq9i2', 'phq9i3', 'phq9i4', 'phq9i5',\n",
    "       'phq9i6', 'phq9i7', 'phq9i8', 'phq9i9', 'stni1', 'stni10a',\n",
    "       'stni11a', 'stni2', 'stni3', 'stni4', 'stni5', 'stni6', 'stni7',\n",
    "       'stni8', 'stni9', 'gad7i1', 'gad7i2', 'gad7i3', 'gad7i4', 'gad7i5',\n",
    "       'gad7i6', 'gad7i7', 'isi1', 'isi2', 'isi3', 'isi4', 'isi5', 'isi6',\n",
    "       'isi7', 'infield', 'work']\n",
    "\n",
    "features_best = ['age', 'ceaPriorTimeWeeks', 'infield', 'phq9i5', 'isi5', 'stni1', 'work', 'gad7i6', 'phq9i4', 'ceaPTWi10']\n",
    "from sklearn.preprocessing import label_binarize\n",
    "              \n",
    "#split data\n",
    "train, test = train_test_split(data_bl_dropna, test_size = .3, random_state=39, stratify = data_bl_dropna['cluster'])\n",
    "\n",
    "Y_train = train['cluster_num']\n",
    "Y_test = test['cluster_num']\n",
    "\n",
    "#create feature sets\n",
    "X_train_exp = train[features_exposure]\n",
    "X_test_exp = test[features_exposure]\n",
    "\n",
    "X_train_mh = train[features_MH]\n",
    "X_test_mh = test[features_MH]\n",
    "\n",
    "X_train_all = train[features_all]\n",
    "X_test_all = test[features_all]\n",
    "\n",
    "X_train_best = train[features_best]\n",
    "X_test_best = test[features_best]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale data algo\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#k fold algo\n",
    "strat_k_fold = StratifiedKFold(n_splits=10)\n",
    "\n",
    "#classifier algos\n",
    "dm_cv = DummyClassifier(strategy='stratified', random_state=39)\n",
    "lr_cv = LogisticRegression(random_state=39, class_weight='balanced')\n",
    "rf_cv = RandomForestClassifier(random_state=39, class_weight='balanced')\n",
    "svm_cv = SVC(kernel='linear', probability=True, class_weight='balanced') \n",
    "knn_cv = KNeighborsClassifier()\n",
    "gb_cv = GradientBoostingClassifier(random_state=39)\n",
    "ab_cv = AdaBoostClassifier(random_state=39)\n",
    "\n",
    "#dic with classifier and feature importance attribute name\n",
    "models_dic = {'dm_cv': (dm_cv, 'none'), \n",
    "              'lr_cv': (lr_cv, 'coef'), \n",
    "              'rf_cv': (rf_cv, 'feature_importance'), \n",
    "              'svm_cv':(svm_cv, 'coef'), \n",
    "              'knn_cv': (knn_cv, 'none'), \n",
    "              'gb_cv': (gb_cv, 'feature_importance'),\n",
    "              'ab_cv': (ab_cv, 'feature_importance')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance(X, y, model_instance, feature_names, fi_name):\n",
    "    #takes in features (X) and classess (y), model, column names for features in X, and name of attribute for feature importance\n",
    "    #returns dictionary of feature names and coef/feature importance values\n",
    "    \n",
    "    feature_importance_dic = {}\n",
    "    \n",
    "    model_instance.fit(X, y)\n",
    "    \n",
    "    if fi_name == 'coef':\n",
    "        coef = model_instance.coef_[0]\n",
    "        feature_importance_dic = dict(zip(feature_names, coef))\n",
    "    if fi_name == 'feature_importance':\n",
    "        coef = model_instance.feature_importances_\n",
    "        feature_importance_dic = dict(zip(feature_names, coef))\n",
    "    if fi_name == 'none':\n",
    "        coef = np.zeros(len(feature_names))\n",
    "        feature_importance_dic = dict(zip(feature_names, coef))\n",
    "    \n",
    "    return feature_importance_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_pipeline(X, y, cv_instance, model_instance, feature_names, fi_name):\n",
    "    \n",
    "    #scale data\n",
    "    data_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    #generate cross-val sets\n",
    "    cv = list(cv_instance.split(X, y))\n",
    "    \n",
    "    #predict class and predict probability \n",
    "    y_pred = cross_val_predict(model_instance, X, y, cv=cv, method='predict')\n",
    "    y_pred_prob = cross_val_predict(model_instance, X, y, cv=cv, method='predict_proba')\n",
    "    \n",
    "    #generate confusion matrix\n",
    "    conf_mat = confusion_matrix(y, y_pred)\n",
    "    print('Confusion matrix:', conf_mat)\n",
    "    \n",
    "    #generate ROC_AUC\n",
    "    #ROC_AUC = metrics.roc_auc_score(y, y_pred_prob[:,1])\n",
    "    #print(\"ROC_AUC: \", ROC_AUC)\n",
    "    \n",
    "    # generate additional metrics\n",
    "    recall = metrics.recall_score(y,y_pred, average='weighted')\n",
    "    precision = metrics.precision_score(y,y_pred, average='weighted')\n",
    "    accuracy = metrics.accuracy_score(y,y_pred)\n",
    "    F1 = metrics.f1_score(y,y_pred, average='weighted')\n",
    "    print(\"Sensitivity/Recall (TPR): \",recall)\n",
    "    print(\"Precision (PPV): \", precision)\n",
    "    print(\"Accuracy: \", accuracy)\n",
    "    print(\"F1:\", F1)\n",
    "    \n",
    "    #determine feature importance\n",
    "    feature_dic = feature_importance(X, y, model_instance, feature_names, fi_name)\n",
    "    \n",
    "    #create dic\n",
    "    data_dic = {}\n",
    "    data_dic['y_pred'] = y_pred\n",
    "    data_dic['y_pred_prob'] = y_pred_prob\n",
    "    data_dic['conf_mat'] = conf_mat\n",
    "    #data_dic['ROC_AUC'] = ROC_AUC\n",
    "    data_dic['recall'] = recall\n",
    "    data_dic['precision'] = precision\n",
    "    data_dic['accuracy'] = accuracy\n",
    "    data_dic['F1'] = F1\n",
    "    \n",
    "    data_dic = {**data_dic, **feature_dic}\n",
    "    \n",
    "    return data_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_set = 'exposure'\n",
    "feature_names = features_exposure\n",
    "\n",
    "data_features_exposure = {}\n",
    "\n",
    "for name, model in models_dic.items():\n",
    "    print(f'{name} model with {feature_set} features:')\n",
    "    data_features_exposure[name + '_' + feature_set] = classification_pipeline(X_train_exp, Y_train, strat_k_fold, model[0], feature_names, model[1])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_set = 'MH'\n",
    "feature_names = features_MH\n",
    "\n",
    "data_features_MH = {}\n",
    "\n",
    "for name, model in models_dic.items():\n",
    "    print(f'{name} model with {feature_set} features:')\n",
    "    data_features_MH[name + '_' + feature_set] = classification_pipeline(X_train_mh, Y_train, strat_k_fold, model[0], feature_names, model[1])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_set = 'all'\n",
    "feature_names = features_all\n",
    "\n",
    "data_features_all = {}\n",
    "\n",
    "for name, model in models_dic.items():\n",
    "    print(f'{name} model with {feature_set} features:')\n",
    "    data_features_all[name + '_' + feature_set] = classification_pipeline(X_train_all, Y_train, strat_k_fold, model[0], feature_names, model[1])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_set = 'best'\n",
    "feature_names = features_best\n",
    "\n",
    "data_features_best = {}\n",
    "\n",
    "for name, model in models_dic.items():\n",
    "    print(f'{name} model with {feature_set} features:')\n",
    "    data_features_best[name + '_' + feature_set] = classification_pipeline(X_train_best, Y_train, strat_k_fold, model[0], feature_names, model[1])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put dics in pandas df \n",
    "final_dic = {**data_features_exposure, **data_features_MH, **data_features_all}\n",
    "data_pandas = pd.DataFrame.from_dict(data = final_dic, orient='index').reset_index()\n",
    "data_pandas.sort_values('F1', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from scipy import interp\n",
    "from itertools import cycle\n",
    "\n",
    "X=X_train_all\n",
    "# Binarize the output\n",
    "y = label_binarize(Y_train, classes=[0, 1, 2])\n",
    "n_classes = y.shape[1]\n",
    "\n",
    "# Add noisy features to make the problem harder\n",
    "random_state = np.random.RandomState(0)\n",
    "n_samples, n_features = X.shape\n",
    "X = np.c_[X, random_state.randn(n_samples, 200 * n_features)]\n",
    "\n",
    "# shuffle and split training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.5,\n",
    "                                                    random_state=0)\n",
    "\n",
    "# Learn to predict each class against the other\n",
    "classifier = OneVsRestClassifier(SVC(kernel='linear', probability=True,\n",
    "                                 random_state=random_state))\n",
    "y_score = classifier.fit(X_train, y_train).decision_function(X_test)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "lw=2\n",
    "colors =['green', 'darkorange', 'red']\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Support Vector Machine multi-class ROC (all features)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### explain features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a SVM classifier\n",
    "#classifier algos\n",
    "dm = DummyClassifier(strategy='stratified', random_state=39)\n",
    "lr = LogisticRegression(random_state=39, class_weight='balanced')\n",
    "rf = RandomForestClassifier(random_state=39, class_weight='balanced')\n",
    "svm = SVC(kernel='linear', probability=True, class_weight='balanced') \n",
    "knn = KNeighborsClassifier()\n",
    "gb = GradientBoostingClassifier(random_state=39)\n",
    "ab = AdaBoostClassifier(random_state=39)\n",
    "\n",
    "model = svm\n",
    "\n",
    "model.fit(X_train_all, Y_train)\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test_all)\n",
    "y_predp = model.predict_proba(X_test_all)\n",
    "y=Y_test\n",
    "\n",
    "# generate additional metrics\n",
    "recall = metrics.recall_score(y,y_pred, average='weighted')\n",
    "precision = metrics.precision_score(y,y_pred, average='weighted')\n",
    "accuracy = metrics.accuracy_score(y,y_pred)\n",
    "F1 = metrics.f1_score(y,y_pred, average='weighted')\n",
    "print(\"Sensitivity/Recall (TPR): \",recall)\n",
    "print(\"Precision (PPV): \", precision)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"F1:\", F1)\n",
    "\n",
    "#generate confusion matrix\n",
    "conf_mat = confusion_matrix(y, y_pred)\n",
    "print('Confusion matrix:\\n', conf_mat)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use Kernel SHAP to explain test set predictions\n",
    "explainer = shap.KernelExplainer(model.predict_proba, X_train_all, link=\"logit\")\n",
    "shap_values = explainer.shap_values(X_test_all, nsamples=100)\n",
    "\n",
    "#plot the SHAP values for the Setosa output of the first instance\n",
    "shap.force_plot(explainer.expected_value[0], shap_values[0][-2,:], X_test_all.iloc[-2,:], link=\"logit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize the effects of all the features\n",
    "shap.summary_plot(shap_values, X_test_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot the SHAP values for the Setosa output of all instances\n",
    "shap.force_plot(explainer.expected_value[0], shap_values[0], X_test_all, link=\"logit\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
